{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled55.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJuQQNMXZOsNOIWPOV0akJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/cross-document_coreference/blob/main/text_analysis_coref60k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oA2EFVEBdpW8",
        "outputId": "d612b4c2-258d-4464-d703-4c611bbf118c"
      },
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download ru_core_news_sm\n",
        "!python -m spacy download ru_core_news_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6f/43037c7bcc8bd8ba7c9074256b1a11596daa15555808ec748048c1507f08/pip-21.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 6.9MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/15/5041473f5d142ee93bf1593deb8f932e27a078f6f04e2020cf44044f72c5/setuptools-56.2.0-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 19.2MB/s \n",
            "\u001b[?25hRequirement already up-to-date: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pip, setuptools\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "  Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "Successfully installed pip-21.1.1 setuptools-56.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 82 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading spacy_legacy-3.0.5-py2.py3-none-any.whl (12 kB)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "  Downloading thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=cfc791a02e40e3a4d227f362cf0bb854afcf47335cd827a915efd35b3442f9cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
            "Successfully built smart-open\n",
            "Installing collected packages: catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "2021-05-12 23:24:12.512886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting ru-core-news-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.0.0/ru_core_news_sm-3.0.0-py3-none-any.whl (17.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.9 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.0.0) (3.0.6)\n",
            "Collecting pymorphy2>=0.9\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.0.0) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (56.2.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.1.1)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2, ru-core-news-sm\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 ru-core-news-sm-3.0.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "2021-05-12 23:24:35.205982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting ru-core-news-md==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.0.0/ru_core_news_md-3.0.0-py3-none-any.whl (43.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 43.9 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-md==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: pymorphy2>=0.9 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-md==3.0.0) (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-md==3.0.0) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-md==3.0.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-md==3.0.0) (0.6.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (56.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (20.9)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (2.10)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->ru-core-news-md==3.0.0) (1.1.1)\n",
            "Installing collected packages: ru-core-news-md\n",
            "Successfully installed ru-core-news-md-3.0.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7UjWjAX7P9d",
        "outputId": "8a1a68ca-5a07-4139-e5fa-18a0a866c9d6"
      },
      "source": [
        "pip install pymorphy2[fast]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting DAWG>=0.8\n",
            "  Downloading DAWG-0.8.0.tar.gz (371 kB)\n",
            "\u001b[K     |████████████████████████████████| 371 kB 6.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp37-cp37m-linux_x86_64.whl size=856055 sha256=ab62be153fbc086b9df214da302b0ad4d6b4c480a63284eaff0a13dc785967a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/51/a4/2de41ff197786537075027c27b479a38da92f50abc86634445\n",
            "Successfully built DAWG\n",
            "Installing collected packages: DAWG\n",
            "Successfully installed DAWG-0.8.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPb5-By9vJOA",
        "outputId": "bdc49355-51d4-4473-d8ee-2d0f1b39b83f"
      },
      "source": [
        "pip install Gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from Gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from Gensim) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from Gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from Gensim) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from smart-open>=1.2.1->Gensim) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->smart-open>=1.2.1->Gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->smart-open>=1.2.1->Gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->smart-open>=1.2.1->Gensim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->smart-open>=1.2.1->Gensim) (2020.12.5)\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA9wDY-2d-pF"
      },
      "source": [
        "import spacy\n",
        "import gensim\n",
        "from gensim.models import Word2Vec \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk import  sent_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBhu8gSAd_6M"
      },
      "source": [
        "nlp = spacy.load('ru_core_news_md')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvjxp5z8ZDc",
        "outputId": "43a438fa-0191-4dc9-b727-31b067c585df"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/neuroleptic_antidepr2.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 23:25:17--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/neuroleptic_antidepr2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11655409 (11M) [text/plain]\n",
            "Saving to: ‘neuroleptic_antidepr2.txt’\n",
            "\n",
            "neuroleptic_antidep 100%[===================>]  11.12M  27.3MB/s    in 0.4s    \n",
            "\n",
            "2021-05-12 23:25:18 (27.3 MB/s) - ‘neuroleptic_antidepr2.txt’ saved [11655409/11655409]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql21vrWnb2qF",
        "outputId": "503da3d4-68f4-4a34-a7c1-3b89a9d08b64"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/rakpobedim_ru2.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 23:25:18--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/rakpobedim_ru2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19072917 (18M) [text/plain]\n",
            "Saving to: ‘rakpobedim_ru2.txt’\n",
            "\n",
            "rakpobedim_ru2.txt  100%[===================>]  18.19M  48.9MB/s    in 0.4s    \n",
            "\n",
            "2021-05-12 23:25:19 (48.9 MB/s) - ‘rakpobedim_ru2.txt’ saved [19072917/19072917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ZudIeTb22Z",
        "outputId": "89a829fd-0ee4-40cb-d0dc-187c2afcbeb4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/hv-info_gepatit2.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 23:25:19--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/scraping/hv-info_gepatit2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18273113 (17M) [text/plain]\n",
            "Saving to: ‘hv-info_gepatit2.txt’\n",
            "\n",
            "hv-info_gepatit2.tx 100%[===================>]  17.43M  47.9MB/s    in 0.4s    \n",
            "\n",
            "2021-05-12 23:25:20 (47.9 MB/s) - ‘hv-info_gepatit2.txt’ saved [18273113/18273113]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpy6V0dtsM79",
        "outputId": "fa0e9074-8bd0-4306-895d-b4667774c85b"
      },
      "source": [
        "!wget https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 23:25:20--  https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140310878 (134M) [application/x-gzip]\n",
            "Saving to: ‘news_upos_cbow_300_2_2017.bin.gz’\n",
            "\n",
            "news_upos_cbow_300_ 100%[===================>] 133.81M  25.3MB/s    in 6.1s    \n",
            "\n",
            "2021-05-12 23:25:27 (21.9 MB/s) - ‘news_upos_cbow_300_2_2017.bin.gz’ saved [140310878/140310878]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3dEmsOH8eOZ"
      },
      "source": [
        "handler = open('neuroleptic_antidepr2.txt', 'r', encoding='utf-8')\n",
        "my_txt = handler.read()\n",
        "handler.close()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4UmH2pucmxK"
      },
      "source": [
        "handler = open('hv-info_gepatit2.txt', 'r', encoding='utf-8')\n",
        "my_txt += handler.read()\n",
        "handler.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBp9WjLNcgsJ"
      },
      "source": [
        "handler = open('rakpobedim_ru2.txt', 'r', encoding='utf-8')\n",
        "my_txt += handler.read()\n",
        "handler.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_8MyfaucZxO",
        "outputId": "94d9b2e3-9def-40ac-e491-a8efbc1e8397"
      },
      "source": [
        "len(my_txt)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27946773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiQH5Q0pZJQZ"
      },
      "source": [
        "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1,3))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e410Dy9KdGqv",
        "outputId": "ce386a55-0058-454b-afbc-73774a0ee77d"
      },
      "source": [
        "!wget https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 23:25:27--  https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140310878 (134M) [application/x-gzip]\n",
            "Saving to: ‘news_upos_cbow_300_2_2017.bin.gz.1’\n",
            "\n",
            "news_upos_cbow_300_ 100%[===================>] 133.81M  23.9MB/s    in 6.5s    \n",
            "\n",
            "2021-05-12 23:25:34 (20.5 MB/s) - ‘news_upos_cbow_300_2_2017.bin.gz.1’ saved [140310878/140310878]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLT6J1ua82fF"
      },
      "source": [
        "posts = my_txt.split('----')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXZdM39Zzais"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "sentences_tokenized = [w.lower() for w in posts]\n",
        "\n",
        "vectorized_txt = tfidf.fit_transform(sentences_tokenized)\n",
        "sentences_tokenized = [tokenizer.tokenize(i) for i in sentences_tokenized]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W44Ejf4ILyxP"
      },
      "source": [
        "from gensim.models import FastText\n",
        "from google.colab import files"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3DaCSYSLbti"
      },
      "source": [
        "ft = FastText(sentences_tokenized, size=100, window=5, min_count=5, workers=4,sg=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYAobGf_ubLC"
      },
      "source": [
        "ft.save('ft_model')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_j-FLzi4vWaM",
        "outputId": "c0a7b14a-77fe-4007-db07-1e4da64f7c0e"
      },
      "source": [
        "files.download('ft_model')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_999ba3ec-6b28-47cb-b73e-c6431e7ed8f3\", \"ft_model\", 92992453)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjXk9HzZL7Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed89c4c6-0945-499a-c3d6-504ace12bb73"
      },
      "source": [
        "ft.most_similar('алимемазин')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('левомепромазин', 0.8782601356506348),\n",
              " ('триоксазин', 0.8759325742721558),\n",
              " ('трифлуоперазин', 0.8414560556411743),\n",
              " ('хлорпромазин', 0.840761661529541),\n",
              " ('пипофезин', 0.8369158506393433),\n",
              " ('зимелидин', 0.8339601755142212),\n",
              " ('тиоридазин', 0.8336536884307861),\n",
              " ('ипрониазид', 0.8322772979736328),\n",
              " ('палиперидон', 0.8278595209121704),\n",
              " ('изокарбоксазид', 0.8273183703422546)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWOUZIx5Mu4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cc7b5b-88b7-400c-c02d-1aefc3444d33"
      },
      "source": [
        "ft.wv.__getitem__('алимемазин')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.2453686 ,  0.56710815,  0.06693438, -0.16957112,  0.18656401,\n",
              "        0.16413006,  0.32660273, -0.3223524 , -0.03784393, -0.24079105,\n",
              "       -0.2768778 , -0.03266587, -0.28471243, -0.13557324, -0.49659124,\n",
              "        0.2568454 ,  0.10839053, -0.00324988, -0.03547192, -0.07265068,\n",
              "        0.23425522, -0.04839876, -0.4392015 ,  0.055676  ,  0.1707488 ,\n",
              "        0.01938497, -0.14036372,  0.13370116, -0.14899142, -0.51764774,\n",
              "       -0.11587782,  0.17604667,  0.44437551,  0.5519726 ,  0.25264975,\n",
              "        0.07480077,  0.7937876 , -0.25629357, -0.17646489,  0.5023675 ,\n",
              "       -0.45949692, -0.15450826, -0.47792   ,  0.22126837, -0.27460843,\n",
              "       -0.3074345 , -0.0726065 , -0.12907557, -0.3015485 , -0.08681021,\n",
              "       -0.5983358 ,  0.7649138 , -0.20182474, -0.52963454,  0.2898467 ,\n",
              "        0.17150718, -0.41079336, -0.41922945,  0.2998531 ,  0.29475224,\n",
              "       -0.42352965,  0.21196015,  0.3379076 , -0.20853049, -0.22989003,\n",
              "       -0.16098188,  0.4679046 ,  0.15750182,  0.22258195, -0.01567311,\n",
              "       -0.43521306, -0.4583589 , -0.21310036,  0.0638552 , -0.03431464,\n",
              "        0.54373074,  0.17447266, -0.22304283, -0.40004843,  0.07664972,\n",
              "        0.18410902, -0.11848826,  0.30165315, -0.33829495, -0.07660147,\n",
              "        0.11661597,  0.00353245, -0.00274825,  0.0147887 ,  0.20735334,\n",
              "       -0.24505585, -0.0187059 ,  0.05664245,  0.12997627, -0.17312159,\n",
              "       -0.3322676 , -0.25800002,  0.13009532, -0.18681936,  0.28315002],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXJmNeDnFJb8"
      },
      "source": [
        "# files.download('small_fasttext60k')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucjN2SXmu_qe"
      },
      "source": [
        "# w2v = gensim.models.KeyedVectors.load_word2vec_format('news_upos_cbow_300_2_2017.bin.gz', binary=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufr_mUmQwc_3"
      },
      "source": [
        "# model = Word2Vec(size=300, min_count=1)\n",
        "# model.build_vocab(sentences_tokenized)\n",
        "# total_examples = model.corpus_count\n",
        "# model.build_vocab([list(w2v.vocab.keys())], update=True)\n",
        "# model.intersect_word2vec_format(\"news_upos_cbow_300_2_2017.bin.gz\", binary=True)\n",
        "# model.train(sentences_tokenized, total_examples=total_examples, epochs=model.iter)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXFz2x3vNSmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab3a571-1998-4965-b2d1-7f255360c4de"
      },
      "source": [
        "cosine_similarity(np.atleast_2d(ft.wv.get_vector('алимемазин')), \\\n",
        "                  np.atleast_2d(ft.wv.get_vector('азалептин')))[0][0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.70144963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSaPsAMzNXcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6898a912-71f6-4c6f-f70e-d9005fb4dfac"
      },
      "source": [
        "cosine_similarity(np.atleast_2d(ft.wv.get_vector('алимемазин')), \\\n",
        "                  np.atleast_2d(ft.wv.get_vector('стул')))[0][0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32482818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWfPCgbmNw3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3064ac54-b477-4371-b335-4690df110801"
      },
      "source": [
        "cosine_similarity(np.atleast_2d(ft.wv.get_vector('дак')), \\\n",
        "                  np.atleast_2d(ft.wv.get_vector('соф')))[0][0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9281227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC3kW8hY5LNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40ce3db-a1eb-4c2a-bcf4-89f381f9802f"
      },
      "source": [
        "cosine_similarity(np.atleast_2d(ft.wv.get_vector('дак')), \\\n",
        "                  np.atleast_2d(ft.wv.get_vector('софосбувир')))[0][0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5488733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDMJTQnwNlWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a56d738f-2413-42dc-b043-b71f8798fee1"
      },
      "source": [
        "cosine_similarity(np.atleast_2d(ft.wv.get_vector('соф')), \\\n",
        "                  np.atleast_2d(ft.wv.get_vector('софосбувир')))[0][0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.53131956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3YeIYgLf9o2"
      },
      "source": [
        "# Модель есть, теперь надо набрать корпус из трех форумов примерно поровну, и чтобы не помереть при разметке."
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sdy4JIXW_Ld"
      },
      "source": [
        "СОВСЕМ НЕМНОЖКО, для начала!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPnaS6Vq3Hxz"
      },
      "source": [
        "short_txt = \" \"\n",
        "handler = open('neuroleptic_antidepr2.txt', 'r', encoding='utf-8')\n",
        "short_txt = handler.read()[:60000]\n",
        "handler.close()\n",
        "\n",
        "handler = open('rakpobedim_ru2.txt', 'r', encoding='utf-8')\n",
        "short_txt += handler.read()[:60000]\n",
        "handler.close()\n",
        "\n",
        "handler = open('hv-info_gepatit2.txt', 'r', encoding='utf-8')\n",
        "short_txt += handler.read()[:60000]\n",
        "handler.close()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WISiAodR9MvG",
        "outputId": "7fa1a79f-8ff0-43ed-81e9-0bb1757b2580"
      },
      "source": [
        "len(short_txt)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11jQB9ave4EV",
        "outputId": "73f65403-789d-42a8-f2bd-9c77d08b08f7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-3v3Ee47avH"
      },
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjqqQEOB0XaO",
        "outputId": "8486f15e-cd36-4a27-9708-dfd0fdde6f38"
      },
      "source": [
        "sample = 'он'\n",
        "print('Одуш', morph.parse(sample)[0].tag.animacy)\n",
        "print('Падеж', morph.parse(sample)[0].tag.case )\n",
        "print('Пол', morph.parse(sample)[0].tag.gender)\n",
        "print('Число', morph.parse(sample)[0].tag.number)\n",
        "print('Лицо', morph.parse(sample)[0].tag.person)\n",
        "print('Часть речи', morph.parse(sample)[0].tag.POS)\n",
        "print('Время', morph.parse(sample)[0].tag.tense)\n",
        "print('Залог', morph.parse(sample)[0].tag.voice)\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Одуш None\n",
            "Падеж nomn\n",
            "Пол masc\n",
            "Число sing\n",
            "Лицо 3per\n",
            "Часть речи NPRO\n",
            "Время None\n",
            "Залог None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLk-dMgV7Ucy",
        "outputId": "0cf7cd82-d835-4c85-aa96-212b0c5060d3"
      },
      "source": [
        "aa = morph.parse(sample)[0]\n",
        "print(aa.tag)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NPRO,masc,3per,Anph sing,nomn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztjqE_Mu04w3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d08c9a0-fbb3-4407-d251-ab68e883629f"
      },
      "source": [
        "doc = nlp('У меня практически нет никаких проблем, и в частности, с лекарством.')\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_, \n",
        "            [child for child in token.children], morph.parse(token.text)[0].tag,\n",
        "          [child for child in token.head.children])\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "У case меня PRON [] PREP [У]\n",
            "меня obl нет VERB [У] NPRO,1per sing,accs [меня, практически, проблем, лекарством, .]\n",
            "практически advmod нет VERB [] ADVB [меня, практически, проблем, лекарством, .]\n",
            "нет ROOT нет VERB [меня, практически, проблем, лекарством, .] PRED,pres [меня, практически, проблем, лекарством, .]\n",
            "никаких det проблем NOUN [] ADJF,Apro plur,gent [никаких]\n",
            "проблем nsubj нет VERB [никаких] NOUN,inan,femn plur,gent [меня, практически, проблем, лекарством, .]\n",
            ", punct лекарством NOUN [] PNCT [,, и, в, с]\n",
            "и cc лекарством NOUN [] CONJ [,, и, в, с]\n",
            "в discourse лекарством NOUN [частности, ,] PREP [,, и, в, с]\n",
            "частности fixed в ADP [] NOUN,inan,femn sing,loct [частности, ,]\n",
            ", punct в ADP [] PNCT [частности, ,]\n",
            "с case лекарством NOUN [] PREP [,, и, в, с]\n",
            "лекарством conj нет VERB [,, и, в, с] NOUN,inan,neut sing,ablt [меня, практически, проблем, лекарством, .]\n",
            ". punct нет VERB [] PNCT [меня, практически, проблем, лекарством, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dd4UU-Dde0K",
        "outputId": "06055210-f96e-4b94-a2e6-638d3b3a1af4"
      },
      "source": [
        "doc = nlp('У меня практически нет никаких проблем, и в частности, с лекарством.')\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "            [child for child in token.children], morph.parse(token.text)[0].tag,\n",
        "          [child for child in token.head.children],)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "У case меня PRON [] PREP [У]\n",
            "меня obl нет VERB [У] NPRO,1per sing,accs [меня, практически, проблем, лекарством, .]\n",
            "практически advmod нет VERB [] ADVB [меня, практически, проблем, лекарством, .]\n",
            "нет ROOT нет VERB [меня, практически, проблем, лекарством, .] PRED,pres [меня, практически, проблем, лекарством, .]\n",
            "никаких det проблем NOUN [] ADJF,Apro plur,gent [никаких]\n",
            "проблем nsubj нет VERB [никаких] NOUN,inan,femn plur,gent [меня, практически, проблем, лекарством, .]\n",
            ", punct лекарством NOUN [] PNCT [,, и, в, с]\n",
            "и cc лекарством NOUN [] CONJ [,, и, в, с]\n",
            "в discourse лекарством NOUN [частности, ,] PREP [,, и, в, с]\n",
            "частности fixed в ADP [] NOUN,inan,femn sing,loct [частности, ,]\n",
            ", punct в ADP [] PNCT [частности, ,]\n",
            "с case лекарством NOUN [] PREP [,, и, в, с]\n",
            "лекарством conj нет VERB [,, и, в, с] NOUN,inan,neut sing,ablt [меня, практически, проблем, лекарством, .]\n",
            ". punct нет VERB [] PNCT [меня, практически, проблем, лекарством, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOm7fPDO8AMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1745bb-3aad-44b7-82d9-2ee8184d7c3a"
      },
      "source": [
        "sample = 'он'\n",
        "print('Одуш', morph.parse(sample)[0].tag.animacy)\n",
        "print('Падеж', morph.parse(sample)[0].tag.case )\n",
        "print('Пол', morph.parse(sample)[0].tag.gender)\n",
        "print('Число', morph.parse(sample)[0].tag.number)\n",
        "print('Лицо', morph.parse(sample)[0].tag.person)\n",
        "print('Часть речи', morph.parse(sample)[0].tag.POS)\n",
        "print('Время', morph.parse(sample)[0].tag.tense)\n",
        "print('Залог', morph.parse(sample)[0].tag.voice)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Одуш None\n",
            "Падеж nomn\n",
            "Пол masc\n",
            "Число sing\n",
            "Лицо 3per\n",
            "Часть речи NPRO\n",
            "Время None\n",
            "Залог None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku0NMgIJomMR"
      },
      "source": [
        "***Разметка для кореференции***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsph7ljhaSyu"
      },
      "source": [
        "topic_list = short_txt.split('\\nTOPIC')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFVyrTNBrxHq",
        "outputId": "09ba1b03-7dda-45ff-f080-edc0bd7e96d2"
      },
      "source": [
        "import re\n",
        "print(re.search(r'[A-Za-zА-Яа-я]', ','))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ETC8YL4msn"
      },
      "source": [
        "# sentences_tokenized = [w.lower() for w in short_posts]\n",
        "# sentences_tokenized = [tokenizer.tokenize(i) for i in sentences_tokenized]\n",
        "# sentences_tokenized[2]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "09ZSqQ2CBRaU",
        "outputId": "6747e9e7-c595-4eb9-d815-ac4ca49981d0"
      },
      "source": [
        "print(len(topic_list))\n",
        "topic_list[1]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nОбсуждаем препарат Рисперидон (Рисполепт, Сперидан)\\n----\\nНЕ знаю, стоило ли мне писать. У меня практически нет никаких проблем, и в частности, с лекарством. По крайней мере врач говорит, что всё идёт как надо. У меня с детства бывают состояния, когда я без видимых причин впадаю в панику, не управляю своими действиями. Странное беспокойство может продолжаться от нескольких мгновений до нескольких суток. Как-то удавалось жить и с этим мириться. Каждый раз, придя в себя, вынуждена придумывать для окружающих более или менее правдоподобное оправдание своим поступкам. Чувствую себя сторонним наблюдателем собственной жизни. В определённый момент страхи стали в основном связаны с учёбой (а ещё с общением). На последнем курсе училища всё это вылилось в невозможность в общем потоке сдать экзамены.\\nОбратились к врачу. Со стороны родителей это делалось с большой неохотой. От чего меня лечат, не уточнили. После пары \"вводных бесед\" назначили небольшую дозировку рисполепта (сказали \"для начала\"...). Принимаю несколько дней. Меня, конечно предупреждали, что появится заторможенность, рассеянность, возможно придётся больше спать. Результат превзошёл ожидания: ужасно кружится голова, руки трясутся, ноги не слушаются. Боюсь пройти по квартире, брать в руки вещи, чтобы ничего не сломать (инцеденты уже были). Рассеянность - Ухитрилась заблудиться возле собственного дома!\\nВрач велела больше спать. Но я сплю как обычно и не часом больше.\\nЖдать ли мне положительных результатов или я просто дура, что подсела на таблетки (так говорят все родственники)?\\n\\nПрошу прощения за такой пространный рассказ о жизни.\\nВпервые решила воспользоваться форумом, ещё нет опыта.\\nЛюди! Если даже я беспокою вас впустую! Если кто-нибудь есть неравнодушный, Будет время - посоветуйте, как мне реагировать на происходящее, что можно почитать на эту тему.\\nМожет, я выбрала не ту тему, чтобы писать в форум. И снова прошу прощения, если таковое возможно.\\n----\\nНадо подумать... сказал(а)\\nЖдать ли мне положительных результатов или я просто дура, что подсела на таблетки (так говорят все родственники)?\\nИсходя из написанного Вами, проблемы все-таки достаточно серьезные, и, видимо, требуют именно психофармакотерапии. Так что таблетки нужны. Но вот какие именно, подбирать дозу, учитывать побочные эффекты - это все должен делать лечащий врач. В принципе, те эффекты, которые Вы описали, могут быть при приеме рисполепта. Эти побочные эффекты могут проходить через несколько дней после начала лечения, могут требовать коррекции дозы, назначение корректоров нейролептической терапии или смены препарата.\\nP.S. Напишите, пожалуйста, как себя чувствуете сейчас? Есть какие-то изменения?\\n----\\nА почему именно назначили рисперидон?! У Вас вероятно наблюдается снижение АД, связанное в адреноблоеирующими свойствами препарата.\\nФлюанксол в низких дозировках, вероятно, мог быть благоприятнее.\\n----\\nПочему-же надо было начинать с тяжелой артиллерии Сонапакс с тормозным компонентом для начала был бы неплох\\n----\\nоднозначно хороший препарат, особенно при лечении параноидной шизофрении.\\n----\\nК сожалению препарат не впечатляет! На нем у меня одна пациентка суициднула! Между рисполептом и азалептином я отдаю преимущество последнему!\\n----\\nподелюсь своими впечатлениями: при биполярном аффективном расстройстве препарат хорошо снимает вязкость мыслей, препятствует образованию бредовых идей, и, как ни странно, приводит к лучшему засыпанию. но основная проблема - это его влияние на повышение пролактина и образование пролактиномы гипофиза. эта проблема у меня проявилась. пришлось принимать бромкриптин - пролактин в норму вошёл, а уменьшилась ли микроаденома ещё не знаю. от рисполепта отказалась на свой страх и риск.\\nесли кто-то здесь сталкивался с гормональными проблемами - поделитесь, пожалуйста, вашим опытом.\\n----\\nКто-нибудь применяет дженерик Торендо ?\\nКакие клинические наблюдения есть?\\n----\\nпробовали знаем. лечили меня рисполептом после санопакса и паксила. side effects один в один как у автора ветки. бросал потом начинал опять не выдержал в итоге и бросил пить окончательно тк от навязчивых мыслей он не избавил а существование отравил еще как\\n----\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_WJFXZm_Lwu"
      },
      "source": [
        "post_list = []\n",
        "sent_list = []\n",
        "for topic_num, topic in enumerate(topic_list):\n",
        "  for post_num, post in enumerate(topic.split('----')):\n",
        "    for sent_num, sent in enumerate(sent_tokenize(post)):\n",
        "      # sent_list.append((tokenizer.tokenize(sent.lower()), sent_num, post_num, topic_num))\n",
        "      if sent.lower():\n",
        "        sent_list.append((sent.lower(), sent_num, post_num, topic_num))\n",
        "# post_list[35] # quote"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gntQTQ0p2apw",
        "outputId": "badeffa6-ab2b-4aae-8f5f-2a0aef7c2af5"
      },
      "source": [
        "len(sent_list)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esN_Oldp7sJj",
        "outputId": "02e65cc1-3226-49c6-c843-e913d2e9b6aa"
      },
      "source": [
        "sent_list[0][1]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaCmridtEUhP",
        "outputId": "2556a277-a34c-47c9-8841-fbc6c769d294"
      },
      "source": [
        "sent_list[10:15]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('на последнем курсе училища всё это вылилось в невозможность в общем потоке сдать экзамены.',\n",
              "  9,\n",
              "  1,\n",
              "  1),\n",
              " ('обратились к врачу.', 10, 1, 1),\n",
              " ('со стороны родителей это делалось с большой неохотой.', 11, 1, 1),\n",
              " ('от чего меня лечат, не уточнили.', 12, 1, 1),\n",
              " ('после пары \"вводных бесед\" назначили небольшую дозировку рисполепта (сказали \"для начала\"...).',\n",
              "  13,\n",
              "  1,\n",
              "  1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEhG-VL23MwI",
        "outputId": "f3d6396f-3b64-426e-a5c8-a29772a7487f"
      },
      "source": [
        "sent = 'я сказал(а) ты пидор'\n",
        "is_ans = 0\n",
        "\n",
        "for i in ['сказал(а)', ') писал:', 'писал(а): ↑']:\n",
        "  is_ans = is_ans + (1 if i in sent else 0) \n",
        "is_ans"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i13--Gw9pASO"
      },
      "source": [
        "coref_df = pd.DataFrame(columns=['TOKEN', 'TOKEN_VECT', 'IS_ANSWER', 'TOPIC_NUM', 'POST_NUM', 'SENT_NUM', 'ANIMACY', 'CASE', 'GENDER', 'PERSON', 'POS', 'DEPENDENCY', 'HEAD',\n",
        "                                  'HEAD_ANIMACY', 'HEAD_CASE', 'HEAD_GENDER',  'HEAD_POS', 'HEAD_VECT', 'SENT_VECT', 'HEAD_CHILDS_VECT', 'NER',\n",
        "                                 'COREFERENCE_CLUSTER', ])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2fyFOMJ2gf6",
        "outputId": "dbd894db-f792-46d2-a796-d83b64e09b24"
      },
      "source": [
        "for sent_info in sent_list:\n",
        "\n",
        "  topic_num = sent_info[3]\n",
        "  post_num = sent_info[2]\n",
        "  sent_num = sent_info[1]\n",
        "\n",
        "  is_ans = 0\n",
        "  \n",
        "  sent = sent_info[0]\n",
        "\n",
        "  is_ans = 0\n",
        "  for i in ['сказал(а)', ') писал:', 'писал(а): ↑']:\n",
        "    is_ans = is_ans + (1 if i in sent else 0) \n",
        "\n",
        "  sent_tokens = tokenizer.tokenize(sent)\n",
        "  spacy_tokens = nlp(sent)\n",
        "\n",
        "  sent_vector = 0\n",
        "  for token in sent_tokens:\n",
        "    try:\n",
        "      sent_vector += ft.wv.__getitem__(token.lower())\n",
        "      sent_vector = sent_vector/len(sent_tokens) if len(sent_tokens) > 0 else 0\n",
        "    except KeyError:\n",
        "      print(token.lower(), 'O__o')\n",
        "  \n",
        "  for token in spacy_tokens:\n",
        "    # if re.search(r'[A-Za-zА-Яа-я]', token.text):\n",
        "    if tokenizer.tokenize(token.text):\n",
        "        morphy = morph.parse(token.text)[0]\n",
        "\n",
        "        app_dict = {}\n",
        "        app_dict['TOKEN'] = token.text\n",
        "        try:\n",
        "          app_dict['TOKEN_VECT'] = ft.wv.__getitem__(token.text.lower()) if token.text else None\n",
        "        except KeyError:\n",
        "          print(token.text.lower(), 'O__o')\n",
        "        app_dict['IS_ANSWER'] = is_ans\n",
        "        app_dict['TOPIC_NUM'] = topic_num \n",
        "        app_dict['POST_NUM'] = post_num \n",
        "        app_dict['SENT_NUM'] = sent_num \n",
        "\n",
        "        app_dict['ANIMACY'] = morphy.tag.animacy\n",
        "        app_dict['CASE'] = morphy.tag.case\n",
        "        app_dict['GENDER'] = morphy.tag.gender\n",
        "        app_dict['PERSON'] = morphy.tag.person\n",
        "        app_dict['POS'] = morphy.tag.POS\n",
        "        app_dict['DEPENDENCY'] = token.dep_ \n",
        "\n",
        "        app_dict['HEAD'] = token.head.text\n",
        "        try:\n",
        "          app_dict['HEAD_VECT'] = ft.wv.__getitem__(token.head.text.lower()) if token.head.text else '-'\n",
        "        except KeyError:\n",
        "          app_dict['HEAD_VECT'] = None\n",
        "          print(token.head.text.lower(), 'here')\n",
        "        app_dict['HEAD_POS'] = token.head.pos_\n",
        "        morphy = morph.parse(token.head.text)[0]\n",
        "        app_dict['HEAD_ANIMACY'] = morphy.tag.animacy\n",
        "        app_dict['HEAD_CASE'] = morphy.tag.case \n",
        "        app_dict['HEAD_GENDER'] = morphy.tag.gender \n",
        "        # app_dict['HEAD_PERSON'] = morphy.tag.person or '-'\n",
        "        app_dict['HEAD_POS'] = morphy.tag.POS\n",
        "        app_dict['SENT_VECT'] = sent_vector\n",
        "        try:\n",
        "          if token.head.children:\n",
        "            app_dict['HEAD_CHILDS_VECT'] = 0\n",
        "            for child in token.head.children:\n",
        "              if re.search(r'[A-Za-zА-Яа-я]', child.text):\n",
        "                app_dict['HEAD_CHILDS_VECT'] += ft[child.text.lower()]\n",
        "            if list(token.head.children):\n",
        "              app_dict['HEAD_CHILDS_VECT'] = app_dict['HEAD_CHILDS_VECT']/len(list(token.head.children))\n",
        "        except (KeyError, ZeroDivisionError):\n",
        "          print(child.text.lower(), 'end')\n",
        "\n",
        "        app_dict['NER'] = 0\n",
        "        app_dict['COREFERENCE_CLUSTER'] = 0\n",
        "        coref_df = coref_df.append(app_dict, ignore_index=True)  \n",
        "    \n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "т.к end\n",
            "т.к end\n",
            "т.к O__o\n",
            "т.к end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "2-е end\n",
            "2-е O__o\n",
            "2-е end\n",
            "2-е end\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "т.к end\n",
            "т.к end\n",
            "т.к O__o\n",
            "т.к end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "2-е end\n",
            "2-е O__o\n",
            "2-е end\n",
            "2-е end\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "0,5 O__o\n",
            "$ here\n",
            "u.s end\n",
            "u.s end\n",
            "u.s end\n",
            "u.s end\n",
            "1.4 O__o\n",
            "$ here\n",
            "u.s end\n",
            "u.s O__o\n",
            "u.s end\n",
            "u.s end\n",
            "- here\n",
            "- here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "1.2 O__o\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "0,5 O__o\n",
            "0,5 O__o\n",
            "$ here\n",
            "u.s end\n",
            "u.s end\n",
            "u.s end\n",
            "u.s end\n",
            "1.4 O__o\n",
            "$ here\n",
            "u.s end\n",
            "u.s O__o\n",
            "u.s end\n",
            "u.s end\n",
            "- here\n",
            "- here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "1.2 O__o\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "0,5 O__o\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "4x7 O__o\n",
            "4x7 O__o\n",
            "4x7 O__o\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "5,5 O__o\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "2,5 O__o\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "* here\n",
            "\n",
            "\n",
            " here\n",
            "8) O__o\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "т.е end\n",
            "1,5 O__o\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "т.е end\n",
            "1,5 O__o\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "- here\n",
            "т.е end\n",
            "т.е end\n",
            "- here\n",
            "- here\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "- here\n",
            "- here\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "... here\n",
            "- here\n",
            "- here\n",
            "т.ч here\n",
            "т.ч O__o\n",
            "т.ч end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "т.ч here\n",
            "т.ч O__o\n",
            "т.ч end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "1р O__o\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            ", here\n",
            ", here\n",
            ", here\n",
            ", here\n",
            "\n",
            "  here\n",
            "т.к end\n",
            "т.к O__o\n",
            "т.к end\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "т.к end\n",
            "т.к O__o\n",
            "т.к end\n",
            "\n",
            " here\n",
            "2,9 here\n",
            "2,9 here\n",
            "2,9 O__o\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "2,9 here\n",
            "2,9 here\n",
            "2,9 O__o\n",
            "т.е O__o\n",
            "т.е here\n",
            "  here\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            ", here\n",
            ", here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            ", here\n",
            ", here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "1-б O__o\n",
            "1-б end\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            ", here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            ", here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "  here\n",
            "\n",
            " here\n",
            "- here\n",
            "\n",
            " here\n",
            "  here\n",
            ". here\n",
            "\n",
            "  here\n",
            "- here\n",
            "- here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "3–4 O__o\n",
            "\n",
            " here\n",
            "\n",
            "  here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            ", here\n",
            "\n",
            " here\n",
            "= here\n",
            "= here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "- here\n",
            "\n",
            " here\n",
            "↑ here\n",
            "\n",
            " here\n",
            "- here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "т.е O__o\n",
            "т.е here\n",
            "т.е O__o\n",
            "т.е here\n",
            "т.е O__o\n",
            "т.е here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "- here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "• here\n",
            "• here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "↑ here\n",
            "- here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            ", here\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е end\n",
            "т.е O__o\n",
            "т.е end\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "s. end\n",
            "s. end\n",
            "s. end\n",
            "s. end\n",
            "s. O__o\n",
            "s. end\n",
            "s. end\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            ", here\n",
            "% here\n",
            "% here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "т.к end\n",
            "т.к end\n",
            "т.к end\n",
            "т.к end\n",
            "т.к O__o\n",
            "т.к end\n",
            "% here\n",
            "% here\n",
            "- here\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "% here\n",
            "% here\n",
            "% here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "& here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "& here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "& here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "\n",
            "\n",
            " here\n",
            "\n",
            "\n",
            " here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "$ here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n",
            "\n",
            " here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "B3G6ZS-h7LJ0",
        "outputId": "15943f43-5d30-4df0-d226-2858a9d7f7eb"
      },
      "source": [
        "coref_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOKEN</th>\n",
              "      <th>TOKEN_VECT</th>\n",
              "      <th>IS_ANSWER</th>\n",
              "      <th>TOPIC_NUM</th>\n",
              "      <th>POST_NUM</th>\n",
              "      <th>SENT_NUM</th>\n",
              "      <th>ANIMACY</th>\n",
              "      <th>CASE</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>PERSON</th>\n",
              "      <th>POS</th>\n",
              "      <th>DEPENDENCY</th>\n",
              "      <th>HEAD</th>\n",
              "      <th>HEAD_ANIMACY</th>\n",
              "      <th>HEAD_CASE</th>\n",
              "      <th>HEAD_GENDER</th>\n",
              "      <th>HEAD_POS</th>\n",
              "      <th>HEAD_VECT</th>\n",
              "      <th>SENT_VECT</th>\n",
              "      <th>HEAD_CHILDS_VECT</th>\n",
              "      <th>NER</th>\n",
              "      <th>COREFERENCE_CLUSTER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>обсуждаем</td>\n",
              "      <td>[-0.35198107, 0.5814818, -0.6922001, -0.654415...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1per</td>\n",
              "      <td>VERB</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>обсуждаем</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>VERB</td>\n",
              "      <td>[-0.35198107, 0.5814818, -0.6922001, -0.654415...</td>\n",
              "      <td>[-0.005098215, 0.17649734, 0.093845055, -0.053...</td>\n",
              "      <td>[-0.99740636, 0.36573833, -0.7532651, -0.01085...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>препарат</td>\n",
              "      <td>[-0.99740636, 0.36573833, -0.7532651, -0.01085...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>masc</td>\n",
              "      <td>None</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>obj</td>\n",
              "      <td>обсуждаем</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>VERB</td>\n",
              "      <td>[-0.35198107, 0.5814818, -0.6922001, -0.654415...</td>\n",
              "      <td>[-0.005098215, 0.17649734, 0.093845055, -0.053...</td>\n",
              "      <td>[-0.99740636, 0.36573833, -0.7532651, -0.01085...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>рисперидон</td>\n",
              "      <td>[-0.21882823, 0.8052027, 0.5637987, -0.1392462...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>anim</td>\n",
              "      <td>nomn</td>\n",
              "      <td>masc</td>\n",
              "      <td>None</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>appos</td>\n",
              "      <td>препарат</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>masc</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[-0.99740636, 0.36573833, -0.7532651, -0.01085...</td>\n",
              "      <td>[-0.005098215, 0.17649734, 0.093845055, -0.053...</td>\n",
              "      <td>[-0.21882823, 0.8052027, 0.5637987, -0.1392462...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>рисполепт</td>\n",
              "      <td>[-0.33769298, 0.671512, 0.539861, -0.22888352,...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>inan</td>\n",
              "      <td>gent</td>\n",
              "      <td>femn</td>\n",
              "      <td>None</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>parataxis</td>\n",
              "      <td>рисперидон</td>\n",
              "      <td>anim</td>\n",
              "      <td>nomn</td>\n",
              "      <td>masc</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[-0.21882823, 0.8052027, 0.5637987, -0.1392462...</td>\n",
              "      <td>[-0.005098215, 0.17649734, 0.093845055, -0.053...</td>\n",
              "      <td>[-0.33769298, 0.671512, 0.539861, -0.22888352,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>сперидан</td>\n",
              "      <td>[0.05934307, 0.71211994, 0.34583476, -0.213859...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>masc</td>\n",
              "      <td>None</td>\n",
              "      <td>PRTS</td>\n",
              "      <td>conj</td>\n",
              "      <td>рисполепт</td>\n",
              "      <td>inan</td>\n",
              "      <td>gent</td>\n",
              "      <td>femn</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[-0.33769298, 0.671512, 0.539861, -0.22888352,...</td>\n",
              "      <td>[-0.005098215, 0.17649734, 0.093845055, -0.053...</td>\n",
              "      <td>[0.019781023, 0.2373733, 0.11527825, -0.071286...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26492</th>\n",
              "      <td>и</td>\n",
              "      <td>[-0.11929728, -0.0030615432, -0.224329, -0.084...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>CONJ</td>\n",
              "      <td>cc</td>\n",
              "      <td>пошлины</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>femn</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[-0.18635513, -0.90914214, 0.529626, -1.112177...</td>\n",
              "      <td>[0.02620858, -0.0037238898, -0.031466015, -0.0...</td>\n",
              "      <td>[0.14148605, -0.22999011, -0.32839295, -0.4938...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26493</th>\n",
              "      <td>таможенные</td>\n",
              "      <td>[0.5437554, -0.6869088, -0.76084983, -1.396614...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>nomn</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>ADJF</td>\n",
              "      <td>amod</td>\n",
              "      <td>пошлины</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>femn</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[-0.18635513, -0.90914214, 0.529626, -1.112177...</td>\n",
              "      <td>[0.02620858, -0.0037238898, -0.031466015, -0.0...</td>\n",
              "      <td>[0.14148605, -0.22999011, -0.32839295, -0.4938...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26494</th>\n",
              "      <td>пошлины</td>\n",
              "      <td>[-0.18635513, -0.90914214, 0.529626, -1.112177...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>femn</td>\n",
              "      <td>None</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nsubj</td>\n",
              "      <td>есть</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>INFN</td>\n",
              "      <td>[-1.0104536, -0.5207962, -0.12965627, -1.68644...</td>\n",
              "      <td>[0.02620858, -0.0037238898, -0.031466015, -0.0...</td>\n",
              "      <td>[-0.27050188, -0.49391568, 0.05964191, -0.7663...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26495</th>\n",
              "      <td>как</td>\n",
              "      <td>[0.30085436, 0.047424514, -0.38781196, -0.9260...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>CONJ</td>\n",
              "      <td>advmod</td>\n",
              "      <td>есть</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>INFN</td>\n",
              "      <td>[-1.0104536, -0.5207962, -0.12965627, -1.68644...</td>\n",
              "      <td>[0.02620858, -0.0037238898, -0.031466015, -0.0...</td>\n",
              "      <td>[-0.27050188, -0.49391568, 0.05964191, -0.7663...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26496</th>\n",
              "      <td>светка</td>\n",
              "      <td>[0.2955255, 0.3631344, -0.7881875, -0.40432668...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>femn</td>\n",
              "      <td>None</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>светка</td>\n",
              "      <td>inan</td>\n",
              "      <td>nomn</td>\n",
              "      <td>femn</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>[0.2955255, 0.3631344, -0.7881875, -0.40432668...</td>\n",
              "      <td>[0.2955255, 0.3631344, -0.7881875, -0.40432668...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26497 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            TOKEN  ... COREFERENCE_CLUSTER\n",
              "0       обсуждаем  ...                   0\n",
              "1        препарат  ...                   0\n",
              "2      рисперидон  ...                   0\n",
              "3       рисполепт  ...                   0\n",
              "4        сперидан  ...                   0\n",
              "...           ...  ...                 ...\n",
              "26492           и  ...                   0\n",
              "26493  таможенные  ...                   0\n",
              "26494     пошлины  ...                   0\n",
              "26495         как  ...                   0\n",
              "26496      светка  ...                   0\n",
              "\n",
              "[26497 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGtB6FGc9ITr"
      },
      "source": [
        "coref_df_anns = coref_df.loc[:, ['TOKEN', 'TOPIC_NUM', 'POST_NUM', 'SENT_NUM', 'IS_ANSWER', 'HEAD', 'NER', 'COREFERENCE_CLUSTER' ]]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDbf0ysWDkb"
      },
      "source": [
        "coref_df.to_csv('coref_fasttext60k.csv', sep=' ', index=False)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88RYff8nbTQB"
      },
      "source": [
        "coref_df_anns.to_csv('coref_df_anns60k.csv', sep=' ', index=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDjOd2g-Pg0"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tSAG8kV8-Rob",
        "outputId": "0e75b3f8-ff65-4848-d756-803b2f40f4e8"
      },
      "source": [
        "files.download('coref_fasttext60k.csv')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_97cadb20-8e17-41c1-91f5-ec317bb19d1a\", \"coref_fasttext60k.csv\", 138191320)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb2JTOA1QJri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1649d5d0-02d9-4a84-f9fb-cce40b602c6a"
      },
      "source": [
        "files.download('coref_df_anns60k.csv')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_33c810e7-5a2d-40b7-bc46-4334a00ce976\", \"coref_df_anns60k.csv\", 1040150)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0pG-kpddYp8"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnyIYAyxi6i"
      },
      "source": [
        "# for topic_num, topic in topic_list:\n",
        "#   post_list = topic.split('----')\n",
        "#   sent_list = [(sent, topic_num) for sent, topic_num in enumerate]\n",
        "#   for sent in sent_list:\n",
        "#     sent_vector = 0\n",
        "#     post_num = sent_dict.get(sent)\n",
        "#     # sent_vector = sum([model.wv.__getitem__(tok.lower())[-1] for tok in sent.split()])\n",
        "#     if 'сказал(а)', 'писал(а)' in sent:\n",
        "#       sent.replace('сказал(а)', 'SOQ')\n",
        "#     for i in sent.split():\n",
        "#       if re.search(r'[A-Za-zА-Яа-я]', i):\n",
        "#         try:     \n",
        "#           sent_vector += ft.wv.__getitem__(i.lower())\n",
        "#         except KeyError:\n",
        "#           print(i.lower(), 111)\n",
        "#     if len(sent.split()) > 0:\n",
        "#       sent_vector = sent_vector/len(sent.split())\n",
        "\n",
        "\n",
        "#     my_sent = nlp(sent)\n",
        "#     for token in my_sent:\n",
        "#       if re.search(r'[A-Za-zА-Яа-я]', token.text):\n",
        "#         morphy = morph.parse(token.text)[0]\n",
        "\n",
        "#         app_dict = {}\n",
        "#         app_dict['TOKEN'] = token.text or '-'\n",
        "#         try:\n",
        "#           app_dict['TOKEN_VECT'] = ft.wv.__getitem__(token.text.lower()) if token.text else '-'\n",
        "#         except KeyError:\n",
        "#           print(token.text.lower(), 'O__o')\n",
        "#         app_dict['POST_NUM'] = post_num or '-'\n",
        "#         app_dict['ANIMACY'] = morphy.tag.animacy or '-'\n",
        "#         app_dict['CASE'] = morphy.tag.case or '-'\n",
        "#         app_dict['GENDER'] = morphy.tag.gender or '-'\n",
        "#         app_dict['PERSON'] = morphy.tag.person or '-'\n",
        "#         app_dict['POS'] = morphy.tag.POS or '-' \n",
        "#         app_dict['DEPENDENCY'] = token.dep_ or '-'\n",
        "\n",
        "#         app_dict['HEAD'] = token.head.text or '-'\n",
        "#         try:\n",
        "#           app_dict['HEAD_VECT'] = ft.wv.__getitem__(token.head.text.lower()) if token.head.text else '-'\n",
        "#         except KeyError:\n",
        "#           app_dict['HEAD_VECT'] = '-'\n",
        "#           print(token.head.text.lower(), 'here')\n",
        "#         app_dict['HEAD_POS'] = token.head.pos_ or '-'\n",
        "#         morphy = morph.parse(token.head.text)[0] or '-'\n",
        "#         app_dict['HEAD_ANIMACY'] = morphy.tag.animacy or '-'\n",
        "#         app_dict['HEAD_CASE'] = morphy.tag.case or '-'\n",
        "#         app_dict['HEAD_GENDER'] = morphy.tag.gender or '-'\n",
        "#         app_dict['HEAD_POS'] = morphy.tag.POS or '-'\n",
        "#         app_dict['SENT_VECTOR'] = sent_vector\n",
        "#         try:\n",
        "#           if token.head.children:\n",
        "#             app_dict['HEAD_CHILDS_VECT'] = 0\n",
        "#             for child in token.head.children:\n",
        "#               if re.search(r'[A-Za-zА-Яа-я]', child.text):\n",
        "#                 app_dict['HEAD_CHILDS_VECT'] += ft[child.text.lower()]\n",
        "#             if list(token.head.children):\n",
        "#               app_dict['HEAD_CHILDS_VECT'] = app_dict['HEAD_CHILDS_VECT']/len(list(token.head.children))\n",
        "#         except (KeyError, ZeroDivisionError):\n",
        "#           print(child.text.lower(), 'end')\n",
        "\n",
        "#         app_dict['NER'] = 0\n",
        "#         app_dict['COREFERENCE_CLUSTER'] = 0\n",
        "#         coref_df = coref_df.append(app_dict, ignore_index=True)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm-d5yaz5mH5"
      },
      "source": [
        "# for topic in topic_list:\n",
        "#   sent_list = topic.split('----')\n",
        "#   for sent in sent_list:\n",
        "#     sent_vector = 0\n",
        "#     post_num = sent_dict.get(sent)\n",
        "#     # sent_vector = sum([model.wv.__getitem__(tok.lower())[-1] for tok in sent.split()])\n",
        "    \n",
        "#     for i in sent.split():\n",
        "#       if re.search(r'[A-Za-zА-Яа-я]', i):\n",
        "#         try:     \n",
        "#           sent_vector += ft.wv.__getitem__(i.lower())\n",
        "#         except KeyError:\n",
        "#           print(i.lower(), 111)\n",
        "#     if len(sent.split()) > 0:\n",
        "#       sent_vector = sent_vector/len(sent.split())\n",
        "\n",
        "#     # if sent_vector == '-' or None or 0:\n",
        "#     #   print(sent)\n",
        "#     my_sent = nlp(sent)\n",
        "#     for token in my_sent:\n",
        "#       if re.search(r'[A-Za-zА-Яа-я]', token.text):\n",
        "#         morphy = morph.parse(token.text)[0]\n",
        "\n",
        "#         app_dict = {}\n",
        "#         app_dict['TOKEN'] = token.text or '-'\n",
        "#         try:\n",
        "#           app_dict['TOKEN_VECT'] = ft.wv.__getitem__(token.text.lower()) if token.text else '-'\n",
        "#         except KeyError:\n",
        "#           print(token.text.lower(), 'O__o')\n",
        "#         app_dict['POST_NUM'] = post_num or '-'\n",
        "#         app_dict['ANIMACY'] = morphy.tag.animacy or '-'\n",
        "#         app_dict['CASE'] = morphy.tag.case or '-'\n",
        "#         app_dict['GENDER'] = morphy.tag.gender or '-'\n",
        "#         app_dict['PERSON'] = morphy.tag.person or '-'\n",
        "#         app_dict['POS'] = morphy.tag.POS or '-' \n",
        "#         app_dict['DEPENDENCY'] = token.dep_ or '-'\n",
        "\n",
        "#         app_dict['HEAD'] = token.head.text or '-'\n",
        "#         try:\n",
        "#           app_dict['HEAD_VECT'] = ft.wv.__getitem__(token.head.text.lower()) if token.head.text else '-'\n",
        "#         except KeyError:\n",
        "#           app_dict['HEAD_VECT'] = '-'\n",
        "#           print(token.head.text.lower(), 'here')\n",
        "#         app_dict['HEAD_POS'] = token.head.pos_ or '-'\n",
        "#         morphy = morph.parse(token.head.text)[0] or '-'\n",
        "#         app_dict['HEAD_ANIMACY'] = morphy.tag.animacy or '-'\n",
        "#         app_dict['HEAD_CASE'] = morphy.tag.case or '-'\n",
        "#         app_dict['HEAD_GENDER'] = morphy.tag.gender or '-'\n",
        "#         # app_dict['HEAD_PERSON'] = morphy.tag.person or '-'\n",
        "#         app_dict['HEAD_POS'] = morphy.tag.POS or '-'\n",
        "#         app_dict['SENT_VECTOR'] = sent_vector\n",
        "#         try:\n",
        "#           if token.head.children:\n",
        "#             app_dict['HEAD_CHILDS_VECT'] = 0\n",
        "#             for child in token.head.children:\n",
        "#               if re.search(r'[A-Za-zА-Яа-я]', child.text):\n",
        "#                 app_dict['HEAD_CHILDS_VECT'] += ft[child.text.lower()]\n",
        "#             if list(token.head.children):\n",
        "#               app_dict['HEAD_CHILDS_VECT'] = app_dict['HEAD_CHILDS_VECT']/len(list(token.head.children))\n",
        "#         except (KeyError, ZeroDivisionError):\n",
        "#           print(child.text.lower(), 'end')\n",
        "\n",
        "#         app_dict['NER'] = 0\n",
        "#         app_dict['COREFERENCE_CLUSTER'] = 0\n",
        "#         coref_df = coref_df.append(app_dict, ignore_index=True)\n"
      ],
      "execution_count": 61,
      "outputs": []
    }
  ]
}