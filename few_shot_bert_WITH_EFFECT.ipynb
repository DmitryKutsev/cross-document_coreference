{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled56.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYLk0nDopNqhl+FImNrVFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/cross-document_coreference/blob/main/few_shot_bert_WITH_EFFECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lchxyQMFPz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85deac25-8c7e-4a56-f56c-0a158134117d"
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/fa/e77a41199168fcf3cd2b75a38b5985b7ced7aded0ff9422f7373385a583e/deeppavlov-0.14.1-py3-none-any.whl (988kB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 24.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 29.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 23.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 25.8MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 28.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 29.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 24.4MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 20.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 20.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 20.2MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 20.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 20.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 624kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 634kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 645kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 655kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 665kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 675kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 686kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 696kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 706kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 716kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 727kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 737kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 747kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 757kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 20.2MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 45.1MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 44.7MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 45.2MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 39.4MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 50.6MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 45.6MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 39.0MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->deeppavlov) (1.0.1)\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 39.8MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.8MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/295101ea5a60f9bee805a3ca422863600ba5cac4e2778ac7bd56efab1231/httptools-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (217kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 62.0MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2020.12.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 38.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 61.3MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: overrides, pytelegrambotapi, prometheus-client, nltk, sacremoses, starlette\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5600 sha256=976128b2abc6235a733bbc807b2c5fdbb51792f4fa267087aaf1437b13721fd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=e5e7cd768b9c9c694a612a26306383603e785a8bfc0867f01a98cc968f337ce0\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=2e8bd536dac1bc33791a078ec8531c1de7ff43ab54c1e021e17e85ac89797b90\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449906 sha256=4052463d2b9cc21171feb5d7cb6827671d9b9b2fb7f6bf8d45daa1e3fdda40bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883999 sha256=503ae5f96f83e68527c363a11277d48e162d4d0540b5ef4b65d0d97d2de7fb4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57244 sha256=612a170e96a1c16d144466f3bfefb1663655df559e929236e8758f582ff7503f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built overrides pytelegrambotapi prometheus-client nltk sacremoses starlette\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: overrides, numpy, scikit-learn, idna, multidict, yarl, pamqp, aiormq, aio-pika, ruamel.yaml, pydantic, pytz, pandas, cryptography, pyopenssl, starlette, fastapi, requests, pytelegrambotapi, uvloop, prometheus-client, h11, httptools, websockets, uvicorn, pymorphy2-dicts-ru, nltk, Cython, pymorphy2-dicts, dawg-python, pymorphy2, rusenttokenize, sacremoses, deeppavlov\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: prometheus-client 0.10.0\n",
            "    Uninstalling prometheus-client-0.10.0:\n",
            "      Successfully uninstalled prometheus-client-0.10.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: Cython 0.29.22\n",
            "    Uninstalling Cython-0.29.22:\n",
            "      Successfully uninstalled Cython-0.29.22\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 deeppavlov-0.14.1 fastapi-0.47.1 h11-0.9.0 httptools-0.1.1 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zv4yPfCkQcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298681fe-93f7-49c8-aa9f-ac32b8a42172"
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.18.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=3b4919d691e1028263ba95ccefd564bdf726828d803db3643ef8067179042720\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IplZsCMwkV60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a453edfe-da82-44cf-843b-826b1350a068"
      },
      "source": [
        "!apt-get --yes install git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IZC4U_KkZrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c9e424-bc25-4c58-a188-1a74df57a239"
      },
      "source": [
        "!pip install git+https://github.com/deepmipt/bert.git@feat/multi_gpu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-devd00ob\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-devd00ob\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp37-none-any.whl size=23581 sha256=8dd214c9c037c2176ee6be35c8ad1665dd3a542ced8956f759950c75a202df3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_tm2ey4c/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p1PH-06ML1S"
      },
      "source": [
        "# # !rm few_test.txt\n",
        "# !rm checkpoint  model.data-00000-of-00001  model.meta   tag.dict  train.txt logs model.index sample_data test.txt valid.txt\n",
        "# !ls"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m8-LRCfn2gm"
      },
      "source": [
        "# !rm train.txt train.txt.1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ArrrVpOpqik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14d0540-43f0-42cd-fd3a-7720bdef00cb"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/train.txt\n",
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/test.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 08:05:42--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45807 (45K) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "\rtrain.txt             0%[                    ]       0  --.-KB/s               \rtrain.txt           100%[===================>]  44.73K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-04-13 08:05:42 (56.1 MB/s) - ‘train.txt’ saved [45807/45807]\n",
            "\n",
            "--2021-04-13 08:05:42--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5195 (5.1K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>]   5.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-13 08:05:42 (53.3 MB/s) - ‘test.txt’ saved [5195/5195]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5OMPb7MZcy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86d6ebf-f5a7-4bc5-a4c3-49f0b5324403"
      },
      "source": [
        "!mv train.txt tmp_train.txt\n",
        "!mv test.txt tmp_test.txt\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  tmp_test.txt  tmp_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBnJDPQvsGm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462adf7f-7627-4c5b-a9eb-90c6aad87eb0"
      },
      "source": [
        "print(open('tmp_train.txt').readlines()[0].split())\n",
        "open('tmp_train.txt').readlines()[10].split()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['клинические', '0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['карипразин', 'B-MED']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnJsw03MsBkG"
      },
      "source": [
        "# handler = open('tmp_train.txt')\n",
        "# wr = open('train.txt', 'w')\n",
        "# # print(len(handler.readlines()))\n",
        "# for i in handler.readlines():\n",
        "#   i = i.replace('\\t', ' ')\n",
        "#   i = i.replace('O', '0')\n",
        "#   wr.write(i)\n",
        "# wr.close()\n",
        "# handler.close"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGUaqBAw2F4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3fd3216-d52b-4b25-c259-2cb6f3f16388"
      },
      "source": [
        "'  '.strip()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPqjzyU0MQt"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOU59D3bz83W"
      },
      "source": [
        "import re"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuWyRwA2hOfY",
        "outputId": "7cc8c4bd-69b5-4ea8-df6d-647accbc2de3"
      },
      "source": [
        "len(open('tmp_test.txt', encoding='utf-8').readlines())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIIuujeKg7BW",
        "outputId": "277d9abe-1409-4a78-bc19-b6c83f855b2b"
      },
      "source": [
        "handler = open('tmp_test.txt', encoding='utf-8')\n",
        "wr = open('test.txt', 'w', encoding='utf-8')\n",
        "ll = ['B-MED', 'I-MED', 'B-EFFECT', 'I-EFFECT', 'B-SICK', 'I-SICK', '0', 0]\n",
        "# print(len(handler.readlines()))\n",
        "for i in handler.readlines():\n",
        "  i = i.replace('\\t', ' ')\n",
        "  if i == '\\n':\n",
        "    # print('yep')\n",
        "    wr.write('\\n')\n",
        "  if i.split() and len(i.split()) > 1:\n",
        "    if re.match(r'\\w+', i) and i.split()[1] in ll:\n",
        "      wr.write(f'{i.split()[0]} {i.split()[1]}\\n')\n",
        "wr.close()\n",
        "handler.close"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcwmrvdihaWD",
        "outputId": "6d85288b-021a-4092-b837-7586922127be"
      },
      "source": [
        "len(open('tmp_test.txt', encoding='utf-8').readlines())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDagxtUKYCkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5605a0b0-f25e-406e-d0c1-a69e6fd24f78"
      },
      "source": [
        "handler = open('tmp_train.txt', encoding='utf-8')\n",
        "wr = open('train.txt', 'w', encoding='utf-8')\n",
        "ll = ['B-MED', 'I-MED', 'B-EFFECT', 'I-EFFECT', 'B-SICK', 'I-SICK', '0', 0]\n",
        "# print(len(handler.readlines()))\n",
        "for i in handler.readlines():\n",
        "  i = i.replace('\\t', ' ')\n",
        "  if i == '\\n':\n",
        "    # print('yep')\n",
        "    wr.write('\\n')\n",
        "  if i.split() and len(i.split()) > 1:\n",
        "    if re.match(r'\\w+', i) and i.split()[1] in ll:\n",
        "      wr.write(f'{i.split()[0]} {i.split()[1]}\\n')\n",
        "wr.close()\n",
        "handler.close"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtgAC81fbm_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047940f6-af52-41ee-85da-332d6b22a848"
      },
      "source": [
        "print(len(open('train.txt').readlines()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjY9b3zHbuA8"
      },
      "source": [
        "# !rm -r logs  tag.dict\ttest.txt  valid.txt\n",
        "# !ls"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcgJe5tp7Yv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d452b5-4a2e-428b-8ab7-a23d12a2fa0c"
      },
      "source": [
        "# !wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/test.txt\n",
        "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/valid.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 08:05:43--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8007 (7.8K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "valid.txt           100%[===================>]   7.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-13 08:05:43 (94.1 MB/s) - ‘valid.txt’ saved [8007/8007]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RtWmauwrjol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97723605-279b-4385-c641-5b7322473575"
      },
      "source": [
        "# !cp train.txt test.txt\n",
        "# !cp train.txt valid.txt\n",
        "# !rm -r logs  tag.dict\ttest.txt  train.txt  valid.txt\n",
        "# !rm test.txt  train.txt  valid.txt\n",
        "!rm tmp_test.txt\ttmp_train.txt \n",
        "# !rm train.txt\n",
        "\n",
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test.txt  train.txt  valid.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX0--aKxkbV4"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from deeppavlov import configs, build_model, train_model\n",
        "\n",
        "with configs.ner.ner_ontonotes_bert_mult.open(encoding='utf8') as f:\n",
        "    ner_config = json.load(f)\n",
        "\n",
        "ner_config['train']['epochs'] = 30 # !!!тут обычно 30, но после того, как все грохнулось, временно будет 10\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
        "ner_config['train']['pytest_batch_size']=4\n",
        "ner_config['device']='GPU'\n",
        "ner_config['dataset_reader']['data_path'] = './'  # directory with train.txt, valid.txt and test.txt files\n",
        "ner_config['metadata']['variables']['NER_PATH'] = './'\n",
        "ner_config['metadata']['download'] = [ner_config['metadata']['download'][-1]]\n",
        "ner_config['train']['batch_size'] = 4"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtl00_qkAAFp"
      },
      "source": [
        "# ner_config"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gj0m8ASAEqT",
        "outputId": "9f42b20e-8aea-40f9-e88a-50550d9f4d2b"
      },
      "source": [
        "ner_config['train']['epochs']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koC6oPCattuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95d2cf98-be69-42b5-e283-794167815b26"
      },
      "source": [
        "# ner_config\n",
        "open('train.txt').readlines()[-1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'расстройств 0\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcQqAsIoN2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ca7627-2bdc-4603-e081-b29d7925afef"
      },
      "source": [
        "ner_model = train_model(ner_config, download=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:19:39.931 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2021-04-13 09:19:39.949 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:19:46.247 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2021-04-13 09:19:46.257 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:20:17.209 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:255: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:20:30.894 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 1.6, \"ner_token_f1\": 7.5404}, \"time_spent\": \"0:00:12\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:250: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 84.8485}, \"time_spent\": \"0:03:15\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 80, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 26.77894948720932}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:23:44.299 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:03:25\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 80, \"impatience\": 1, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.5517}, \"time_spent\": \"0:06:38\", \"epochs_done\": 1, \"batches_seen\": 40, \"train_examples_seen\": 158, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 12.906967115402221}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:27:06.877 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:06:48\", \"epochs_done\": 1, \"batches_seen\": 40, \"train_examples_seen\": 158, \"impatience\": 2, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 94.6524}, \"time_spent\": \"0:10:00\", \"epochs_done\": 2, \"batches_seen\": 60, \"train_examples_seen\": 236, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.94917688369751}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:30:28.668 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:10:09\", \"epochs_done\": 2, \"batches_seen\": 60, \"train_examples_seen\": 236, \"impatience\": 3, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 98.4848}, \"time_spent\": \"0:13:17\", \"epochs_done\": 3, \"batches_seen\": 80, \"train_examples_seen\": 314, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.688548564910889}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:33:45.377 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:13:26\", \"epochs_done\": 3, \"batches_seen\": 80, \"train_examples_seen\": 314, \"impatience\": 4, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 92.3497}, \"time_spent\": \"0:16:21\", \"epochs_done\": 3, \"batches_seen\": 100, \"train_examples_seen\": 392, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.866679012775421}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:36:49.701 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:16:30\", \"epochs_done\": 3, \"batches_seen\": 100, \"train_examples_seen\": 392, \"impatience\": 5, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 95.4545}, \"time_spent\": \"0:19:37\", \"epochs_done\": 4, \"batches_seen\": 120, \"train_examples_seen\": 472, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.464854264259339}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:40:06.143 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:19:47\", \"epochs_done\": 4, \"batches_seen\": 120, \"train_examples_seen\": 472, \"impatience\": 6, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 95.339}, \"time_spent\": \"0:22:49\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 550, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 11.537431299686432}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:43:17.220 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:22:58\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 550, \"impatience\": 7, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 93.3824}, \"time_spent\": \"0:26:03\", \"epochs_done\": 6, \"batches_seen\": 160, \"train_examples_seen\": 628, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.115032315254211}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:46:31.515 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:26:12\", \"epochs_done\": 6, \"batches_seen\": 160, \"train_examples_seen\": 628, \"impatience\": 8, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.3158}, \"time_spent\": \"0:28:52\", \"epochs_done\": 7, \"batches_seen\": 180, \"train_examples_seen\": 706, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.70204793214798}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:49:20.617 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:29:01\", \"epochs_done\": 7, \"batches_seen\": 180, \"train_examples_seen\": 706, \"impatience\": 9, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 89.5833}, \"time_spent\": \"0:32:04\", \"epochs_done\": 7, \"batches_seen\": 200, \"train_examples_seen\": 784, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.717777872085572}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:52:32.914 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:32:14\", \"epochs_done\": 7, \"batches_seen\": 200, \"train_examples_seen\": 784, \"impatience\": 10, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 91.6168}, \"time_spent\": \"0:35:12\", \"epochs_done\": 8, \"batches_seen\": 220, \"train_examples_seen\": 864, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.394034904241561}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:55:40.190 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:35:21\", \"epochs_done\": 8, \"batches_seen\": 220, \"train_examples_seen\": 864, \"impatience\": 11, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 93.8462}, \"time_spent\": \"0:38:26\", \"epochs_done\": 9, \"batches_seen\": 240, \"train_examples_seen\": 942, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.585325014591216}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 09:58:54.753 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:38:35\", \"epochs_done\": 9, \"batches_seen\": 240, \"train_examples_seen\": 942, \"impatience\": 12, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 92.0}, \"time_spent\": \"0:41:17\", \"epochs_done\": 10, \"batches_seen\": 260, \"train_examples_seen\": 1020, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 7.943526422977447}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:01:45.945 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:41:27\", \"epochs_done\": 10, \"batches_seen\": 260, \"train_examples_seen\": 1020, \"impatience\": 13, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 80.8824}, \"time_spent\": \"0:44:33\", \"epochs_done\": 11, \"batches_seen\": 280, \"train_examples_seen\": 1098, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 12.387423861026765}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:05:01.28 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:44:42\", \"epochs_done\": 11, \"batches_seen\": 280, \"train_examples_seen\": 1098, \"impatience\": 14, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.3636}, \"time_spent\": \"0:47:36\", \"epochs_done\": 11, \"batches_seen\": 300, \"train_examples_seen\": 1176, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.054335474967957}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:08:04.705 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:47:45\", \"epochs_done\": 11, \"batches_seen\": 300, \"train_examples_seen\": 1176, \"impatience\": 15, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 91.8605}, \"time_spent\": \"0:50:36\", \"epochs_done\": 12, \"batches_seen\": 320, \"train_examples_seen\": 1256, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.187949740886689}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:11:03.912 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:50:45\", \"epochs_done\": 12, \"batches_seen\": 320, \"train_examples_seen\": 1256, \"impatience\": 16, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 93.6}, \"time_spent\": \"0:53:59\", \"epochs_done\": 13, \"batches_seen\": 340, \"train_examples_seen\": 1334, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 11.41912346482277}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:14:26.968 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:54:08\", \"epochs_done\": 13, \"batches_seen\": 340, \"train_examples_seen\": 1334, \"impatience\": 17, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 97.7273}, \"time_spent\": \"0:56:39\", \"epochs_done\": 14, \"batches_seen\": 360, \"train_examples_seen\": 1412, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 7.967360770702362}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:17:06.939 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"0:56:48\", \"epochs_done\": 14, \"batches_seen\": 360, \"train_examples_seen\": 1412, \"impatience\": 18, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 88.1818}, \"time_spent\": \"1:00:06\", \"epochs_done\": 15, \"batches_seen\": 380, \"train_examples_seen\": 1490, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 12.28017041683197}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:20:34.90 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:00:15\", \"epochs_done\": 15, \"batches_seen\": 380, \"train_examples_seen\": 1490, \"impatience\": 19, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.2617}, \"time_spent\": \"1:03:10\", \"epochs_done\": 15, \"batches_seen\": 400, \"train_examples_seen\": 1568, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 8.59315824508667}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:23:38.741 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:03:19\", \"epochs_done\": 15, \"batches_seen\": 400, \"train_examples_seen\": 1568, \"impatience\": 20, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 92.4138}, \"time_spent\": \"1:06:17\", \"epochs_done\": 16, \"batches_seen\": 420, \"train_examples_seen\": 1648, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.049947077035904}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:26:44.998 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:06:26\", \"epochs_done\": 16, \"batches_seen\": 420, \"train_examples_seen\": 1648, \"impatience\": 21, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.063}, \"time_spent\": \"1:09:22\", \"epochs_done\": 17, \"batches_seen\": 440, \"train_examples_seen\": 1726, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.097075867652894}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:29:50.348 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:09:31\", \"epochs_done\": 17, \"batches_seen\": 440, \"train_examples_seen\": 1726, \"impatience\": 22, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 87.156}, \"time_spent\": \"1:12:25\", \"epochs_done\": 18, \"batches_seen\": 460, \"train_examples_seen\": 1804, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.907114279270171}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:32:53.562 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:12:34\", \"epochs_done\": 18, \"batches_seen\": 460, \"train_examples_seen\": 1804, \"impatience\": 23, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 98.7179}, \"time_spent\": \"1:15:51\", \"epochs_done\": 19, \"batches_seen\": 480, \"train_examples_seen\": 1882, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.336736679077148}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:36:19.516 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:16:00\", \"epochs_done\": 19, \"batches_seen\": 480, \"train_examples_seen\": 1882, \"impatience\": 24, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 82.1429}, \"time_spent\": \"1:18:43\", \"epochs_done\": 19, \"batches_seen\": 500, \"train_examples_seen\": 1960, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.322799777984619}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:39:11.288 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:18:52\", \"epochs_done\": 19, \"batches_seen\": 500, \"train_examples_seen\": 1960, \"impatience\": 25, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 90.2439}, \"time_spent\": \"1:21:34\", \"epochs_done\": 20, \"batches_seen\": 520, \"train_examples_seen\": 2040, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 10.094784307479859}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:42:02.219 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:21:43\", \"epochs_done\": 20, \"batches_seen\": 520, \"train_examples_seen\": 2040, \"impatience\": 26, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 92.8994}, \"time_spent\": \"1:24:32\", \"epochs_done\": 21, \"batches_seen\": 540, \"train_examples_seen\": 2118, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 8.00070481300354}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:45:00.461 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:24:41\", \"epochs_done\": 21, \"batches_seen\": 540, \"train_examples_seen\": 2118, \"impatience\": 27, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 98.2456}, \"time_spent\": \"1:27:57\", \"epochs_done\": 22, \"batches_seen\": 560, \"train_examples_seen\": 2196, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 11.407921421527863}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:48:25.529 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:28:06\", \"epochs_done\": 22, \"batches_seen\": 560, \"train_examples_seen\": 2196, \"impatience\": 28, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 94.5455}, \"time_spent\": \"1:31:09\", \"epochs_done\": 23, \"batches_seen\": 580, \"train_examples_seen\": 2274, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.69557489156723}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:51:37.29 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:31:18\", \"epochs_done\": 23, \"batches_seen\": 580, \"train_examples_seen\": 2274, \"impatience\": 29, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.8553}, \"time_spent\": \"1:34:06\", \"epochs_done\": 23, \"batches_seen\": 600, \"train_examples_seen\": 2352, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 9.02174544930458}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:54:34.581 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n",
            "2021-04-13 10:54:35.656 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:34:15\", \"epochs_done\": 23, \"batches_seen\": 600, \"train_examples_seen\": 2352, \"impatience\": 30, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 90.6977}, \"time_spent\": \"1:37:21\", \"epochs_done\": 24, \"batches_seen\": 620, \"train_examples_seen\": 2432, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 9.77868938446045}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:57:48.879 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:37:30\", \"epochs_done\": 24, \"batches_seen\": 620, \"train_examples_seen\": 2432, \"impatience\": 31, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 93.662}, \"time_spent\": \"1:40:09\", \"epochs_done\": 25, \"batches_seen\": 640, \"train_examples_seen\": 2510, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 7.847043454647064}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:00:37.679 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:40:18\", \"epochs_done\": 25, \"batches_seen\": 640, \"train_examples_seen\": 2510, \"impatience\": 32, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 95.3488}, \"time_spent\": \"1:43:30\", \"epochs_done\": 26, \"batches_seen\": 660, \"train_examples_seen\": 2588, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 11.240196371078492}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:03:58.535 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:43:39\", \"epochs_done\": 26, \"batches_seen\": 660, \"train_examples_seen\": 2588, \"impatience\": 33, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 92.0354}, \"time_spent\": \"1:46:53\", \"epochs_done\": 27, \"batches_seen\": 680, \"train_examples_seen\": 2666, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 9.635083174705505}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:07:21.352 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:47:02\", \"epochs_done\": 27, \"batches_seen\": 680, \"train_examples_seen\": 2666, \"impatience\": 34, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 96.3235}, \"time_spent\": \"1:49:46\", \"epochs_done\": 27, \"batches_seen\": 700, \"train_examples_seen\": 2744, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 9.015826314687729}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:10:14.244 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:49:55\", \"epochs_done\": 27, \"batches_seen\": 700, \"train_examples_seen\": 2744, \"impatience\": 35, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 88.8889}, \"time_spent\": \"1:52:52\", \"epochs_done\": 28, \"batches_seen\": 720, \"train_examples_seen\": 2824, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 10.677964109182358}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:13:20.620 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:53:01\", \"epochs_done\": 28, \"batches_seen\": 720, \"train_examples_seen\": 2824, \"impatience\": 36, \"patience_limit\": 100}}\n",
            "{\"train\": {\"eval_examples_count\": 4, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 97.8102}, \"time_spent\": \"1:56:06\", \"epochs_done\": 29, \"batches_seen\": 740, \"train_examples_seen\": 2902, \"head_learning_rate\": 0.006666666828095913, \"bert_learning_rate\": 1.3333333656191827e-05, \"loss\": 7.814503729343414}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:16:34.656 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the ner_f1 of 1.6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 86.8941}, \"time_spent\": \"1:56:15\", \"epochs_done\": 29, \"batches_seen\": 740, \"train_examples_seen\": 2902, \"impatience\": 37, \"patience_limit\": 100}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:18:13.224 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2021-04-13 11:18:40.604 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n",
            "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 1.5564, \"ner_token_f1\": 2.3339}, \"time_spent\": \"0:00:12\"}}\n",
            "{\"test\": {\"eval_examples_count\": 8, \"metrics\": {\"ner_f1\": 2.5397, \"ner_token_f1\": 1.8072}, \"time_spent\": \"0:00:06\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:19:00.894 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2021-04-13 11:19:28.737 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg4inJipERTm",
        "outputId": "6bbd948e-eea4-4eee-9bde-6e7c8f7cbb73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ner_model.save()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 11:19:32.114 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc2HqRCXqmV1",
        "outputId": "39524b99-16c1-4995-c209-d68dc10f5c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ner_model([\"какое-то не лекарство\", \"пью леонезит 1 месяц\", \"варкрафт 2 интересная игра\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['какое', '-', 'то', 'не', 'лекарство'],\n",
              "  ['пью', 'леонезит', '1', 'месяц'],\n",
              "  ['варкрафт', '2', 'интересная', 'игра']],\n",
              " [['B-MED', 'B-EFFECT', 'B-MED', 'I-EFFECT', 'I-EFFECT'],\n",
              "  ['B-MED', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT'],\n",
              "  ['B-MED', 'I-EFFECT', 'B-EFFECT', 'B-MED']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEec-hQRrBVh"
      },
      "source": [
        "nanika = ner_model(['Паксил норм. Принимал около года, щас перерыв. \\\n",
        "  Синдром отмены не то чтобы совсем отсутствует, но мне особых непрятностей не доставил. \\\n",
        "  Еще тироксин в качестве антидепрессанта хорош, хотя формально показания у него другие.'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9yNpVOB8VzS",
        "outputId": "5a999c97-4a37-4e80-cab1-b9c3959aa403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(zip(nanika[0][0], nanika[1][0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Паксил', 'B-SICK'),\n",
              " ('норм', 'B-MED'),\n",
              " ('.', 'I-EFFECT'),\n",
              " ('Принимал', 'B-MED'),\n",
              " ('около', 'I-EFFECT'),\n",
              " ('года', 'B-MED'),\n",
              " (',', 'I-EFFECT'),\n",
              " ('щас', 'B-MED'),\n",
              " ('перерыв', 'B-MED'),\n",
              " ('.', 'I-EFFECT'),\n",
              " ('Синдром', 'I-EFFECT'),\n",
              " ('отмены', 'B-MED'),\n",
              " ('не', 'I-EFFECT'),\n",
              " ('то', 'B-MED'),\n",
              " ('чтобы', 'I-EFFECT'),\n",
              " ('совсем', 'B-MED'),\n",
              " ('отсутствует', 'B-SICK'),\n",
              " (',', 'B-MED'),\n",
              " ('но', 'I-EFFECT'),\n",
              " ('мне', 'I-EFFECT'),\n",
              " ('особых', 'I-EFFECT'),\n",
              " ('непрятностей', 'B-SICK'),\n",
              " ('не', 'I-EFFECT'),\n",
              " ('доставил', 'I-EFFECT'),\n",
              " ('.', 'I-EFFECT'),\n",
              " ('Еще', 'I-EFFECT'),\n",
              " ('тироксин', 'I-EFFECT'),\n",
              " ('в', 'B-MED'),\n",
              " ('качестве', 'B-EFFECT'),\n",
              " ('антидепрессанта', 'I-EFFECT'),\n",
              " ('хорош', 'I-EFFECT'),\n",
              " (',', 'I-EFFECT'),\n",
              " ('хотя', 'I-EFFECT'),\n",
              " ('формально', 'B-MED'),\n",
              " ('показания', 'I-EFFECT'),\n",
              " ('у', 'I-EFFECT'),\n",
              " ('него', 'I-EFFECT'),\n",
              " ('другие', 'B-SICK'),\n",
              " ('.', 'I-EFFECT')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FiXz5hf-Yh"
      },
      "source": [
        "# !rm checkpoint -r model.data-00000-of-00001  model.meta logs\ttag.dict     model.index\t\t       sample_data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9RdJzwj6nvC",
        "outputId": "bb710f67-6d38-4ec3-f8bf-7b10fc4909fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  model.data-00000-of-00001  model.meta  test.txt   valid.txt\n",
            "logs\t    model.index\t\t       tag.dict    train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IBV1raHdl05",
        "outputId": "017bcf7c-cc0e-4b2d-81ff-fff164a9a01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "for i in os.listdir():\n",
        "  print(i)\n",
        "  files.download(i)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".config\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_78875c39-9e83-4b9c-9325-00a2d357d18f\", \".config\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "logs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_52166626-5a0e-4ed0-9c3a-fe35e25de5f8\", \"logs\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "valid.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7527ede8-206a-44c6-a3d0-e0d6e1e4066c\", \"valid.txt\", 8007)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_db24f9cc-8885-4d76-acdb-f7c8385e4b97\", \"train.txt\", 45755)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model.data-00000-of-00001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_24ba852c-3f73-4843-ade6-a34fddbe1da4\", \"model.data-00000-of-00001\", 1422382516)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tag.dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8ccc4795-3ebd-4d59-92ca-6c78e94fb88b\", \"tag.dict\", 67)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model.meta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4177e978-28b2-4207-9275-ce54e49eb91f\", \"model.meta\", 8450156)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model.index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a6368908-b7f0-4f2e-b0f1-fb9242907d4f\", \"model.index\", 15018)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "test.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7fe4328c-39c6-4613-92a0-f4171d246e16\", \"test.txt\", 4479)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d6f38d16-2268-4183-9bcd-12f40ecf472e\", \"checkpoint\", 85)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En3hWVLsgc2v"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gwr7dB8VFel"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}