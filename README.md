
# Извлечение кросс-текстовой анафоры из русскоязычного пользовательского контента в медицинской сфере.

# Cross-document anaphora extraction from medicine-related content generated by Russian users.

## Вступление.

Извлечение данных из пользовательского медицинского контента - важная задача, позволяющая решить, или упростить решение для множества задач в медицине. Такие задачи, как извлечение отзывов, и иной информации о препаратах, или проведение диагностики на имеющихся данных о лечении заболеваний, дополняют методики лечения. На основе обработанных данных составляются рекомендательные и консалтинговые системы, помогающие врачам поставить диагноз, или подобрать наиболее подходящий препарат. Разрешение анафоры - важная составляющая для большинства систем извлечения данных из текстов. 

Анафора - зависимость между интерпретацией какой-то одной сущности в тексте от другой, встретившейся в том же тексте ранее. Упоминание, встретившееся первым, называют антецедентом, а следующее за ним упоминание того же объекта - анафором. Отношения между антецедентом и анафором можно назвать кореферентными.
Например:

  ```md 
  А кто принимал респеридон расскажите плз как у вас с либидо, было ли сильноеснижение или нет? 
  А также очень интересно как влияет он на депрессивную составляющую..?
  ```

Здесь местоимение “он” является анафором, и ссылается на антецедент, респеридон.
Существует близкая к разрешению анафоры задача - разрешение кореференции. Различие заключается в том, что в случае с анафорой мы рассматриваем конкретный анафор, и подбираем для него подходящий антецедент, в случае же с разрешением кореференции мы собираем все упоминания какой-либо сущности в один кластер.

Например:

```md 
Admin сказал(а) 19.9.2006, 0:29:
Обсуждаем препарат Тиаприд 
Может ли тиаприд вызвать головокружение, принимаю его 2й месяц?
```

```md 
Лилу сказал(а) 27.4.2008, 10:23:
Знаю, что тиапридал применяется при алкоголизме для купирования агрессивности.
Есть ли у кого-нибудь опыт применения этого препарата у пожилых людей?
```
  
Здесь можно объединить Тиаприд и Тиапридал в один кластер, так как они ссылаются на один и тот же препарат. Разрешение анафоры можно рассматривать также как подзадачу к разрешению кореференции, кластеризовав все найденные в текстах упоминания, что также затрагивается подробнее в этой работе.
Нахождение кореференциальных связей может применяться во множестве систем, помимо медицинских. Например, системы машинного перевода, извлечение именованных сущностей, классификация событий, и многие другие.
 



## Анафора и процесс разрешения.

Самый распостраненный тип анафоры подразумевает связи местоимения (реже существительного) с именованной сущностью, или упоминанием этой сущности. Такой тип анафоры называют прономинальной.

Существуют связи, в которых и анафор, и антецедент являются существительными (или, в некоторых случаях, именными группами существительного), например:

```md 
Знаю, что тиапридал применяется при алкоголизме для купирования агрессивности.
Есть ли у кого-нибудь опыт применения этого препарата у пожилых людей?
```

Различают также анафоры, находящиеся внутри одного предложения, и анафоры, члены которых находятся в разных предложениях (интрасентенциальные, и интерсентенциальные). 
В основном в системах разрешения анафоры в качестве анафора рассматривают только именные группы существительных. Хотя бывают случаи, когда в качестве антецедента выступают глагольные группы, целые предложения, или участки дискурса[1]. Также большинство исследований рассматривает анафоры с кореферентными связями в пределах нескольких предложений одного текста. 

Сами системы разрешения анафоры можно разделить на системы с использованием внешних источников знаний[18, 19], правиловые системы [5], системы на основе алгоритмов машинного обучения[7, 8], и гибридные системы[3]. 

Правиловые системы отбирают подходящих кандидатов в антецеденты на основании допусков и ограничений, например согласование по гендеру и числу, созависимость в синтаксическом дереве и т.д.[9].

Набор признаков для систем машинного обучения зачастую выглядит аналогично признакам, которые учитываются в правилах rule-based подходов:
- морфологические признаки (род, число, падеж часть речи)
- синтаксические (контекст, зависимости главного слова именной/прономинальной группы)
- семантические (эмбеддинги контекста)
- дистанционные (дистанция между словами, предложениями)

В исследованиях кореференции явно прослеживается разделение на кросс-текстовую кореференцию, и кореференцию в рамках одного текста. В кросс-текстовых методах документы расположены независимо, у них разные авторы, и соответственно отсутствует линейный порядок событий и упоминаемых сущностей. Лексически расходящиеся выражения могут быть связанными, и наоборот, лексически похожие не иметь таких связей.

В отличии от кореференции, редко можно встретить исследования кросс-текстовой анафоры, в связи с тем, что, как и было упомянуто ранее, большинство работ рассматривают связки антецедент - анафор в рамках нескольких предложений. В случае с пользовательским контентом, этот термин приобретает актуальность, так как сообщения на форумах имеют различных авторов и зачастую могут содержать в себе рассуждения на совершенно различные темы, разрывая линейность текста. В данной работе под термином "текст" мы будем иметь ввиду один(??) пользовательский пост на форуме, и искать кореферентные связи между анафором и антецедентом между постами.


## Обзор предыдущих работ
  
В основе работ по разрешению кореференции часто лежат вероятностные статистические модели (Charniak 1998), в качестве классификаторов используются (если рассматривать классические методы машинного обучения), такие модели, как деревья решений или логистическая регрессия.

Здесь можно выделить два основных подхода - бинарная классификация и ранжирование. Основное различие заключается в том, что при определении антецедента, ранжирование учитывает уже имеющиеся в одном классе с анафорой антецеденты, а бинарная классификация рассматривает только один конкретный антецедент и одну анафору, не учитывая других связей при принятии решения. В качестве классификаторов используются (если рассматривать классические методы машинного обучения), такие модели, как Деревья решений или Логистическая регрессия. 

Также в последнее время часто встречаются модели на основе алгоритмов глубокого обучения, таких как LSTM, BERT и ELMO[10, 11, 12].
Встречается множество исследований [Lee et al. (2012), Barhom S. (2019)], описывающих разрешение кросс-текстовой кореференции, в то время как разрешение анафоры, в основном, описывается с учетом дистанции в несколько предложений между анафором и антецедентом. В исследованиях по снятию кореференции и анафоры имеется разграничение, порой довольно незначительное, что в некоторых случаях они пересекаются, и бывает, эти понятия путают.

Под разрешением кореференции в основном имеют ввиду кластеризацию именованных сущностей, или событий в одном или нескольких текстах, когда под разрешением анафоры подразумевают связь между анафором (в основном это какая-либо именованная сущность) и антецедентом (в основном это местоимения, реже существительные). Эти задачи можно слить в одну, если после разрешения анафоры слить в классы все пары антецедент-анафор, ссылающиеся на одну и ту же сущность в рамках текста, корпуса, или, как иногда выражаются, в рамках реального мира.

Обработка текста является важной деталью при решении задач компьютерной лингвистики методами машинного обучения. В исследовании [15], например, описывается замена местоимений (личные, рефлексивные, и релятивные) на их антецеденты в процессе обработке текста для обучения модели (также используется модель fastText ля векторизации). 
Для первичного разрешения анафоры используется инструмент An@phora (http://ling.go.mail.ru/anaphora). Затем в тех предложениях, где сработало разрешение анафоры, анафор заменяется на антецедент. Модель обучается на парах предложений, с заменой и без. В случае отсутствия антецедента, местоимение отсеивается, как стоп-слово. В результате, при формировании эмбеддингов слов и контекста, модель, обученная на таких парах предложений, лучше различает векторную близость анафора и антецедента.
В исследованиях явления анафоры в англоязычных текстах выделяются отдельные паттерны для определения кореферентных связей. Например,присутствует термин для связующей анафоры (bridging anaphora)[19, 26]. В определении таких типов анафоры извлекаются препозиционные (X of Y) и посессивные структуры (Y’s X), антецедент ищется при помощи лексико-семантических связей, часто с применением внешних словарей и систем хранения знаний.

Зачастую, наличие связь между анафором и антецедентом можно определить только зная значения слов, которые их представляют. Это особенно часто встречается в случаях, когда анафор представлен существительным, например:

```md
Сонапакс с тормозным компонентом для начала был бы неплох. 
Однозначно хороший нейролептик, особенно при лечении параноидной шизофрении.
```
В этом примере можно понять, что "нейролептик" может являться анафором, и иметь связь с названием лекарства, "Сонопакс", только зная, что сонопакс является медицинским препаратом, а нейролептик - это класс медицинских препаратов. Если система сможет связать эти два понятия, то разрешение анафоры представляется возможным. Поэтому часто в менее узкоспециализированных исследованиях (особенно ранних) использовали лексические системы хранения знаний, такие как WordNet[21]. Однако, такие системы извлекали только информацию о наличии/отсутствии связи, и появились решения, хранящие более широкий набор семантической и синтактической информации, такие как Ontonotes[23] и ARRENAU[22].

В корпусе Ontonotes[23] есть ряд своих ограничений. Например, не размечены синглтоны, связи с абстрактными объектами, и ссылки на могие классы объектов[23]. В системе ARRENAU[22], в отличии от Ontonotes[23], были размечены синглтоны и эксплетивы.

Есть и русскоязычные лексические системы хранения знаний, например wiki-ru-wordnet (https://wiki-ru-wordnet.readthedocs.io/) – семантическая сеть типа WordNet для русского языка, составленная из данных русского Викисловаря (https://ru.wiktionary.org/).
По мере распространения семантико-лексических систем, широкое применение при разрешении анафоры получили графовые методы с использованием векторных представлений слов[25]. 

  

## Сбор и подготовка данных.

Данные для обучения классификаторов были взяты с форумов (https://neuroleptic.ru/, https://mneploho.net/forum/1002-1, https://www.hv-info.ru/ и http://www.rakpobedim.ru), и размечены как вручную, так и автоматически.
При скачивании тексты разделялись на топики (символом "TOPIC") и посты (разметкой "-----").

В качестве синтаксического парсера использовалась модель библиотеки spacy (https://spacy.io/models/ru, ru_core_news_md).
Морфологическим анализатором служила библиотека pymorphy2 (https://pymorphy2.readthedocs.io/en/stable/).

Для векторизации окружения и контекста используется предобученная модель fastText, разработанная компанией Facebook, в дистрибутиве библиотеки Gensim (open source software released under the GNU LGPLv2.1 license) для языка Python. 

В процессе токенизации текст разбивался иерархически на топики, посты, предложения, и токены. Разбиение на топики и посты реализовывалось автоматически по разметке, определенной при скачивании текстов. Такенизация на предложения и токены осуществлялась с помощью библиотеки NLTK (https://www.nltk.org , Natural Language Toolkit).

При обработке определялось, присутствует ли в посте цитирование какого-то из предыдущих постов топика с помощью ключевых слов 'сказал(а)', ') писал:', 'писал(а): ↑'. 


Датафрейм содержит следующую информацию:

```md
  - TOKEN - строковое представление всех токена в тексте. 
  
  - TOKEN_VECT - изначально fastText-вектор токена, после обработки в эту колонку помещается значение косинусного
  расстояния до семантической оси токенов(см. дальше расчет сем. осей).
  
  - IS_ANSWER - бинарый признак, 1 или 0. Один значит, что в посте есть цитирование, ноль - наоборот.
  
  - TOPIC_NUM - номер топика
  
  - POST_NUM - номер поста внутри топика (каждый новый топик счетчик сбрасывается и посты считаются с начала)
  
  - SENT_NUM - номер предложения внутри топика.
  
  - TOKEN_NUM - номер токена внутри топика.
  
  - ANIMACY - признак одушевленности/неодушевленности (парсер pymorphy2).
  
  - СASE - падеж (парсер pymorphy2).
  
  - GENDER - пол (парсер pymorphy2).
  
  - PERSON - лицо (парсер pymorphy2).
  
  - POS - часть речи (парсер pymorphy2).
  
  - NUMBER - число (парсер pymorphy2).
  
  - DEPENDENCY - тип синтаксической зависимости (парсер Spacy).
  
  - HEAD - главное слово в синсинтаксическом дереве (парсер Spacy).
  
  - HEAD_ANIMACY - признак одушевленности/неодушевленности гавного слова (парсер pymorphy2).
  
  - HEAD_CASE - падеж главного слова (парсер pymorphy2).
  
  - HEAD_GENDER - пол главного слова(парсер pymorphy2).
  
  - HEAD_POS - часть речи главного слова(парсер pymorphy2).
  
  - HEAD_VECT - fastText-вектор главного слова токена, после обработки в эту колонку помещается значение косинусного 
  расстояния до семантической оси главных слов(см. дальше расчет сем. осей).
  
  - SENT_VECT - fastText-вектор главного слова всего предложения, после обработки в эту колонку помещается значение 
  косинусного расстояния до семантической оси предложений(см. дальше расчет сем. осей).
  
  - HEAD_CHILDS_VECT - fastText-вектор всех зависимых слов для главного слова токена.
  
  - NER - размеченное значение сущности. 1 - название препарата, именованная сущность. 2 - анафор, 
  представленный существительным, такие слова как "препарат", или "лекарство". 3- анафор, представленный местоимением, 
  например "он", "него", "его". 0 - нет кореферентной связи с медицинскими препаратами.
  
  - COREFERENCE_CLUSTER - номер антецедента, начиная с начала топика. В случае, если входящий токен является 
  антецедентом - ему присваивается собственный номер. Если это анафор, то ему присваивается номер его антецедента.
  ```

Названия препаратов (например, "серковель", "сиозсин", и тд) размечались, как класс "1" в столбце NER. В столбце "COREFERENCE_CLUSTER" присваивался собственный номер индекса.
Так как антецедентов в течении топика, как правило, встречалось несколько, кандидаты рассматривались в следующем порядке приоритезации:

  - В одном предложении.
  - В одном посте.
  - В заглавном сообщение топика.
  - В соседних постах.
 
Цитаты можно не рассматривать, как исключительный случай, потому что они входят в состав поста на всех трех форумах.
Всего в датасете порядка 18000 токенов, из которых размечено 629 названий препаратов, которые и будут рассматриваться как потенциальные антецеденты. 

Анафоров размечено 349 (117 наречий и оставшиеся 232 существительные). В числе размеченных потенциальных анафоров попадались и не относящиеся к какому-либо антецеденту в пределах форума, такие анафоры были размечены как нулевые.

## Модели

Первостепенная задача в большинстве исследований компьютерной лингвистики - это перевод текста в численное представление. 
Появляются возможности подключать математический аппарат, и обрабатывать численные данные, закодированные из текста. Наиболее простой метод для векторизации текста - TF-IDF: Term Frequency-Inverse Document Frequency[27].

Tf-IDF считает частоту появления слова в конкретном тексте документа относительно его частоты появления во всей коллекции обрабатываемых текстов, что интуитивно понятно, исходя из названия. Это позволяет снизить значимость слов, которые употребляются во всем корпусе, относительно слов, часто употребляемых в конкретном тексте. Метод используется и до сих пор, однако большая размерность векторов, и потеря информации о совстречаемости  являются его ключевыми недостатками, притом довольно существенными.
Можно решить проблему совстречаемости, добавив частотные н-граммы в словарь модели, но это сильно увеличит размерность векторов.

Широкое распространение получили алгоритмы вероятностного тематического моделирования, такие как Latent Dirichlet allocation (LDA)[29]. Модель представляет текст в виде матрицы размерностью k x N, где k - количество лемм в словаре корпуса, N -количество текстов. Метод LDA относится к классу Байесовских методов, и строит вероятностные распределения нахождения определенной темы в тексте корпуса, и появления слова в тексте с определенной темой. Существенный минус состоит в том, что на больших датасетах Latent Dirichlet allocation  требует много времени и ресурсов для вычислений.

В 2013 году появилась работа [28], описывающая алгоритм Word2vec, в котором были решены некоторые недостатки предыдущих методов. Word2vec обучатся с помощью нейронной сети со скрытым нелинейным слоем. Сравнительно простая архитектура позволяет обучать модель быстрее, не задействуя большого количества ресурсов.
В работе было представлено два варианта алгоритмов:Continuous Bag of Words (CBOW) и Skip-gram. Архитектура CBOW предсказывает слово по контексту заданного размера, Skip-gram наоборот, обучается на предсказание контекста по заданному слову.

Позже была опубликована модель с похожей архитектурой, fastText[30], в которой слово представляется как сумма векторов его н-граммов. 

В основном, Word2vec и fastText показывают близкие результаты в решении различных задач компьютерной лингвистики, с попеременным небольшим перевесом. Ссылаясь на исследование [31], можно сказать,что Word2vec немного уступает модели fastText в производительности, и векторизации редко встречающихся в корпусе слов, и в этой работе мы будем использовать для векторизации модель fastText.



В исследовании как для векторизации текста, так и в качестве классификаторов используются различные модели машинного обучения.


## Метод семантических осей.

Обычно в методах ранжирования для разрешения анафоры и кореференции в качестве признаков рассчитывается косинусная дистанция между анафором и потенциальным антецедентом. Для этого необходимо рассчитать попарно близости каждой пары, и провести сравнение скорингов. Для ускорения процесса, и упрощения анализа зависимостей, я решил применить метод семантических осей, описанный в [14] (глава 20.4.1 Semantic Axis Methods).

Изначально этот метод использовался для решения задачи распознавания тональностей. Для формирования семантической оси выбирались сидовые множества ярко окрашенных глаголов. Отдельно отбирались позитивные и негативные глаголы, например, для позитивного множества {любить, дружить, обожать, и тд..}, а негативное - {неавидеть, убить, уничтожить}. Извлекались векторы этих глаголов, и для каждого множества счиатлась усредненная сумма. Далее для глаголов, тональность которых была размечена, рассчитывалось косинусное расстояние до каждой из осей, и на этих данных обучался классификатор тональностей.

Задача разрешения анафоры не так близка к задаче определения тональностей, как, например, к разрешению кореференции. Интуиция использования данного метода состоит в том, чтобы собрать ось с векторами основных антецедентов (антецедент в заглавном сообщении темы на форуме, или ближайший), и использовать в качестве признака косинусное расстояние векторов сущностей и этой оси.

Для каждого из значений TOKEN_VECT, HEAD_CHILDS_VECT, SENT_VECT, HEAD_VECT рассчитывались сидовые множества. Как правило, в первом посте каждого топика содержится название препарата, и тема для обсуждения. В общем случае это модерируемое сообщение, написанное по шаблону:

  - "Обсуждаем препарат анальгин(производитель Фарма-инк)." Из каждого первого предложения топика(на данный момент размечено 5 топиков) извлекался анафор, его главное слово, и зависимые слова. Для каждого знаения отдельно берется вектор, и также векторизуется все предложение. Формула расчета каждого из сидовых множеств:

![f1]

Здесь ![f2] - результирующий вектор сидового множества,  - вектор токена, предложения, главного слова, или зависимых слов главного слова, а ![f4]  - количество топиков.

Значения TOKEN_VECT, HEAD_CHILDS_VECT, SENT_VECT, HEAD_VECT для каждого токена считаются по формуле:

![f5]



## Метрики оценки системы

Работы по оценке систем анафоры и кореференции используют различные критерии. При расчете метрик часто разделяют типы местоимений. Например оцениваются только личные, посессивные и рефлексивные местоимения, а также учитывается максимальное расстояние между анафором и антецедентом[17].

К сожалению, не так много исследований описывают расчет ошибок систем разрешения анафоры для русского языка. В 2014 году был проведен форум U-EVAL-2014: Evaluating anaphora and coreference resolution for Russian, посвященный оценке систем разрешения анафоры и кореференции для русских текстов. Участникам форума высылался набор данных, на котором они использовали свои системы.
Отдельно оценивались разрешение анафоры и кореференция. Для оценки разрешения анафоры использовались метрики: recall, precision и F-measure (полнота, точность, и F-мера).
Для оценки разрешения кореференции: MUC, B3, CEAF и F-measure.

Данная работа посвящена в первую очередь разрешению анафоры, поэтому рассмотрим более подробно оценку систем для разрешения именно анафоры. метрика precision рассчитывается по формуле:


![f6]

где ![f7] - пары антецедент - анафор, распознанные системой верно, а  - все пары, распознанные системой, как имеющие анафорическую связь.
Соответственно, формула для критерия recall выглядит и расшифровывается следующим образом:


![f9]


где ![f10] - пары антецедент - анафор, распознанные системой верно, а ![f11] - пары, имеющие анафорическую связь, но не распознанные системой, или распознанные ошибочно, и пары, распознанные верно.

И, наконец, Ф-мера:

![f12]

где ![f13] и ![f14]  - точность и полнота.


## Эксперименты

В задаче разрешения анафоры используется широкий набор инструментов. Это методы, основанные на наборах правил, классическом машинном обучении, их комбинации, а так же методы глубокого обучения. В нашей задаче в качестве бэйзлайна мы будем использовать правиловый алгоритм, затем подключим алгоритмы машинного обучения.
Учитывая специфику русского языка, а так же иерархичности текста в социальных форумах, связанных с медицинской тематикой, можно проследить ряд закономерностей, по которым был реализован алгоритм из правил по выбору подходящего антецедента. 

Алгоритм состоит из следующих шагов:

`(я сделаю потом нормальный алгоритм, его интуюцию и блок-схему, но пока опишу словами)`

  - Извлекаются индексы всех топиков датасета.
  - Ведется итерация по всем индексам, для каждого:
     * Извлекается количество постов в топике, и предложений в каждом посте.
     * Итерация идет по каждому предложению поста, для каждого:
         * Извлекаются все анафоры в предложении.
         * Извлекаются все антецеденты в предложении.
         * Если анафоров нет, берется следующее предложение.
         * Если анафоры есть:
             * Проверяется наличие антецедентов в предложении, первым берется самый дальний от анафора (первый с начала предложения), проверяется соответствие по числу. Если ни один из кандидатов не соответствует по числу, анафору присваивается нулевой класс.
             * Если антецедентов нет в предложении, рассматриваются все антецеденты, встречающиеся в предыдущих предложениях поста. В этом случае берется ближайший к анафору антецедент, и так же проверяется на соответствие по числу. В случае несоответствия, присваивается нулевой класс.
             * Если антецедентов нет в посте, берется самый верхний кандидат начиная с начала топика, как правило это заглавное сообщение темы. 

Самая базовая версия алгоритма показала следующий результат, с учетом использавания разметки при извлечении анафоров (антецедент присваивал алгоритм):
```md 
0.5663265306122449  precision
0.6166666666666667  recall
0.5904255319148937  f-score
```

Чтобы проверить, как алгоритм работает без использования размеченных данных при извлечении анафоров, в качества признака для извлечения анафоров можно сменить на часть речи, но в таком случае теряются анафоры-существительные. 
Результат получился лучше, но следует иметь ввиду, что обрабатывалось меньшее количество данных.


```md 
0.6666666666666666  precision
0.6190476190476191  recall
0.6419753086419754  f-score
```

Оба варианта можно использовать в качестве бейзлайна, и такой результат сопоставим с результатами, описанными в исследованиях аналогичных методов.
Следует отметить, что у правиловых алгоритмов (и этот не испключение) есть существенное слабое место - результативность может падать с появлением новых данных.

Зачастую в разрешение анафоры и кореференции используется попарная классификация, но интересно было попробовать предсказания классов на датасете с векторами и сериализованными морфологическими признаками в качестве предиктора, и номером токена антецедента в качестве предскзываемого класса.
Лучшие резльтаты показывала модель K-nearest Neighbors, со следующими метриками:

```md
0.4878048780487805  precision
0.8333333333333334  recall
0.6153846153846153  f-score
``` 

Следующей была модель RandomForest, показавшая следующий результат:
```md
0.42857142857142855  precision
0.9  recall
0.5806451612903225  f-score
``` 
Остальные модели справились хуже, и правиловый бейзлайн перебить не удалось.

Далее применялся метод попарного извлечения антецедентов и анафоров из всего набора данных, в качестве целевой переменной использовался бинарный признак (связь есть, либо ее нет). 

В качестве признаков в итоговом варианте использовались: Номер топика, номер предложения, номер токена, вектор токена, вектор предложения, часть речи, и вектор главного слова именной группы. 

Для каждого анафора, как и для каждого антецедента формировался вектор из факторизованных признаков. Затем, для каждой пары вычисляласть косинусая близость векторов. Чтобы не переобучить модели на антипримерах, для каждого анафора отбиралось 3 ближайших антецедента.
При извлечении анафоров с учетом разметки, классификатор K-nearest Neighbors получил:


```md
0.8305084745762712  precision
0.8596491228070176  recall
0.8448275862068966  f-score
``` 
И близкий результат получился у модели DecisionTree:

```md
0.819672131147541  precision
0.8771929824561403  recall
0.8474576271186439  f-score
```
При извлечении только местоимений по части речи, получилисть следующие результаты:
 - K-nearest Neighbors:
 
```md
0.9545454545454546  precision
0.7777777777777778  recall
0.8571428571428572  f-score
```
 - DecisionTree:
 
 ```md
0.8  presicion
0.7407407407407407  recall
0.7692307692307692  f-score
```
Бейзлайн удалось перебить, и результаты ощутимо улучшились. Остается вопрос, как определить связь между антецедентами и анафорами-существительными. Для этой задачи можно использовать нейросетевые модели глубокого обучения, или, например, онтологические системы хранения знаний.


## Выводы
В результате

## Дискуссия
`coming soon`



-----
[1] http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.6235&rep=rep1&type=pdf
ANAPHORA RESOLUTION: THE STATE OF THE ART, Ruslan Mitkov

Hirst, Graeme. 1981.Anaphora in natural language understanding. Berlin Springer Verlag,
1981.

[2] https://www.aclweb.org/anthology/W16-0711.pdf
Error analysis for anaphora resolution in Russian: new challenging issues
for anaphora resolution task in a morphologically rich language
Svetlana Toldova Ilya Azerkovich Anna Roytberg

[3] http://www.dialog-21.ru/media/3913/gureenkovaoaetal.pdf
Complex Approach towards
Algoritm Learning for Anaphora
Resolution in Russian Language
Gureenkova O. A.,
Batura T. V. ,
Kozlova A. A.,
Svischev A. N.

[4] https://arxiv.org/pdf/1805.10163.pdf
Context-Aware Neural Machine Translation Learns Anaphora Resolution
Elena Voita
University of Amsterdam, Netherlands
Pavel Serdyukov
Rico Sennrich

[5] http://www.dialog-21.ru/media/4829/inshakovaes-167.pdf
AN ANAPHORA RESOLUTION SYSTEM FOR RUSSIAN BASED ON ETAP-4 LINGUISTIC PROCESSOR1 Inshakova E. S

[6] https://www.aclweb.org/anthology/J13-4004.pdf
Jurafsky D., Lee H., Chang A., Peirsman Y., Chambers N., Surdeanu M. (2013), Deterministic Coreference Resolution Based on Entity-Centric, Precision-Ranked
Rules, Association for Computational Linguistics, Vol. 39, N 4, pp. 885–916.


[7] http://www.dialog-21.ru/digests/dialog2014/materials/pdf/Kamenskaya%D0%9C%D0%90.pdf
Kamenskaya М. А., Khramoin I. V., Smirnov I. V. (2014), Data-driven Methods
for Anaphora Resolution of Russian, Computational Linguistics and Intellectual Technologies: Papers from the Annual International Conference “Dialogue”
(2014), Issue 13 (20), pp. 241–250.

http://www.dialog-21.ru/digests/dialog2014/materials/pdf/ProtopopovaEV.pdf
[8] Protopopova E. V., Bodrova A. A., Volskaya S. A., Krylova I. V., Chuchunkov A. S.,
Alexeeva S. V., Bocharov V. V., Granovsky D. V. (2014), Anaphoric Annotation and
Corpus-Based Anaphora Resolution: An Experiment, Computational Linguistics
and Intellectual Technologies: Papers from the Annual International Conference
“Dialogue” (2014), Issue 13 (20), pp. 562–571

[9] http://www.dialog-21.ru/media/4829/inshakovaes-167.pdf
An anaphora resolution system for Russian based on ETAP-4 linguistic processor

[10] https://arxiv.org/pdf/1706.02256.pdf [Submitted on 7 Jun 2017 (v1), last revised 21 Jul 2017 (this version, v2)] A Mention-Ranking Model for Abstract Anaphora Resolution Ana Marasović, Leo Born, Juri Opitz, Anette Frank

[11] https://arxiv.org/pdf/2004.07898.pdf
[Submitted on 16 Apr 2020 (v1), last revised 24 Jun 2020 (this version, v3)] Bridging Anaphora Resolution as Question Answering Yufang Hou

[12] https://www.aclweb.org/anthology/2021.eacl-main.116.pdf ChEMU-Ref: A Corpus for Modeling Anaphora Resolution in the Chemical Domain
Biaoyan Fang, Christian Druckenbrodt, Saber A Akhondi, Jiayuan He, Timothy Baldwin, Karin Verspoor

[13] Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright © 2020. All
rights reserved. Draft of December 30, 2020. глава про разрешение кореференции
https://web.stanford.edu/~jurafsky/slp3/21.pdf

[14] https://web.stanford.edu/~jurafsky/slp3/20.pdf 20.4.1 Semantic Axis Methods
Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright © 2020. All rights reserved. Draft of December 30, 2020. CHAPTER 20 Lexicons for Sentiment, Affect, and Connotation

[15] https://publications.hse.ru/mirror/pubs/share/folder/omioiyt0dk/direct/196474574.pdf Koslowa O., Kutuzov A.
Improving Distributional Semantic Models Using Anaphora Resolution during Linguistic Preprocessing

[16]  https://www.aclweb.org/anthology/W16-0711.pdf Error analysis for anaphora resolution in Russian: new challenging issues for anaphora resolution task in a morphologically rich language
Svetlana Toldova, Ilya Azerkovich, Alina Ladygina, Anna Roitberg, Maria Vasilyeva

[17] C. Barbu. 2002. Error analysis in anaphora resolution.
In LREC.
[18] https://www.researchgate.net/publication/292851003_RU-EVAL-2014_Evaluating_anaphora_and_coreference_resolution_for_Russian U-EVAL-2014: Evaluating anaphora and coreference resolution for Russian

[19] https://hal.archives-ouvertes.fr/hal-03001157/document Integrating knowledge graph embeddings to improve mention representation for bridging anaphora resolution Onkar Pandit , Pascal Denis and Liva Ralaivola

[20] https://www.aclweb.org/anthology/W03-2607.pdf R Bunescu, Associative anaphora resolution: A web-based approach 

[21] Fellbaum, Christiane (2005). WordNet and wordnets. In: Brown, Keith et al. (eds.), Encyclopedia of Language and Linguistics, Second Edition, Oxford: Elsevier, 665-670

[22] https://www.aclweb.org/anthology/W18-0702.pdf Anaphora Resolution with the ARRAU Corpus
Massimo Poesio, Yulia Grishina, Varada Kolhatkar, Nafise Moosavi, Ina Roesiger, Adam Roussel, Fabian Simonjetz, Alexandra Uma, Olga Uryupina, Juntao Yu, Heike Zinsmeister

[23] S. S. Pradhan, E. Hovy, M. Marcus, M. Palmer,
L. Ramshaw, and R. Weischedel. 2007a. Ontonotes:
A unified relational semantic representation. International Journal on Semantic Computing, 1(4):405–
419.

[24] Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and CoNLL - Shared Task, pages
1–40, Jeju Island, Korea. Association for Computational Linguistics.

[25] William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and
applications. cite arxiv:1709.05584Comment: Published in the IEEE Data Engineering Bulletin, September
2017; version with minor corrections.

[26] https://www.aclweb.org/anthology/N13-1111.pdf Global Inference for Bridging Anaphora Resolution Yufang Hou1 , Katja Markert2 , Michael Strube1

[27] Sparck Jones, Karen. "A statistical interpretation of term specificity and
its application in retrieval." Journal of documentation 28.1 (1972): 11-
21.
[28] https://arxiv.org/pdf/1301.3781.pdf Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation
of word representations in vector space. CoRR, abs/1301.3781, 2013.

[29] https://ai.stanford.edu/~ang/papers/nips01-lda.pdf  Latent Dirichlet Allocation David M. Blei Andrew Y. Ng  Michael I. Jordan

[30] https://arxiv.org/abs/1607.04606 P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information

[31] https://link.springer.com/article/10.1186/s12859-018-2543-1 

[f1]: http://chart.apis.google.com/chart?cht=tx&chl=E_sid=\frac{\sum_n^i{E\imath}}{n}
[f2]: http://chart.apis.google.com/chart?cht=tx&chl=E_sid
[f3]: http://chart.apis.google.com/chart?cht=tx&chl=Ei
[f4]: http://chart.apis.google.com/chart?cht=tx&chl=n
[f5]: http://chart.apis.google.com/chart?cht=tx&chl=score_w=cos(E_w,E_sid)
[f6]: http://chart.apis.google.com/chart?cht=tx&chl=P=\frac{M}{S}
[f7]: http://chart.apis.google.com/chart?cht=tx&chl=M
[f8]: http://chart.apis.google.com/chart?cht=tx&chl=S
[f9]: http://chart.apis.google.com/chart?cht=tx&chl=R=\frac{M}{G}
[f10]: http://chart.apis.google.com/chart?cht=tx&chl=M
[f11]: http://chart.apis.google.com/chart?cht=tx&chl=G
[f12]: http://chart.apis.google.com/chart?cht=tx&chl=Fscore=\frac{2PR}{P+R}
[f13]: http://chart.apis.google.com/chart?cht=tx&chl=P
[f14]: http://chart.apis.google.com/chart?cht=tx&chl=R

