{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed8e79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe5f0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21cb7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get --yes install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "909de0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/deepmipt/bert.git@feat/multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "139fbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt install libglib2.0-0 libfontconfig1 libxrender1\n",
    "!apt install wget unzip nano --assume-yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bb3085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\tonstart.log  onstart.sh  test.txt  train.txt  valid.txt\r\n"
     ]
    }
   ],
   "source": [
    "!rm tmp_test.txt tmp_train.txt\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2126a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/train.txt\n",
    "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/test.txt\n",
    "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fd16f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\tonstart.log  onstart.sh  test.txt  train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e70fda08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['прегабалином B-MED',\n",
       " 'Из 0',\n",
       " 'положительных 0',\n",
       " 'моментов 0',\n",
       " 'уже 0',\n",
       " 'чувствуется 0',\n",
       " 'прокогнитивный 0',\n",
       " 'эффект 0',\n",
       " 'зрение 0',\n",
       " 'стало 0',\n",
       " 'четким 0',\n",
       " 'После 0',\n",
       " 'принятия 0',\n",
       " 'прегабалина B-MED',\n",
       " 'настроение B-EFFECT',\n",
       " 'первое 0',\n",
       " 'время 0',\n",
       " 'так 0',\n",
       " 'вообще 0',\n",
       " 'повышенное I-EFFECT',\n",
       " 'Пока 0',\n",
       " 'напрягает 0',\n",
       " 'только 0',\n",
       " 'слабость I-EFFECT',\n",
       " 'появилась 0',\n",
       " 'физическая B-EFFECT',\n",
       " 'слабость I-EFFECT',\n",
       " 'Это 0',\n",
       " 'от 0',\n",
       " 'блокады 0',\n",
       " 'адренорецепторов 0',\n",
       " 'Может 0',\n",
       " 'быть 0',\n",
       " 'пройдёт 0',\n",
       " 'Принемал 0',\n",
       " '2 0',\n",
       " 'месяца 0',\n",
       " 'по 0',\n",
       " '1.5 0',\n",
       " 'мг 0',\n",
       " 'Эфекта 0',\n",
       " 'к 0',\n",
       " 'сожалению 0',\n",
       " 'не 0',\n",
       " 'было 0',\n",
       " 'Через 0',\n",
       " 'меяц 0',\n",
       " 'приема 0',\n",
       " 'неделю 0',\n",
       " 'была 0',\n",
       " 'сильная 0',\n",
       " 'бессонница B-EFFECT',\n",
       " 'Пробывал 0',\n",
       " 'пить 0',\n",
       " '3 0',\n",
       " 'мг 0',\n",
       " 'но 0',\n",
       " 'усил 0',\n",
       " 'затормож 0',\n",
       " 'Он 0',\n",
       " 'долго 0',\n",
       " 'накапливается 0',\n",
       " 'и 0',\n",
       " 'надо 0',\n",
       " 'долго 0',\n",
       " 'ждать 0',\n",
       " 'прежде 0',\n",
       " 'чем 0',\n",
       " 'понимать 0',\n",
       " 'есть 0',\n",
       " 'эфект 0',\n",
       " 'или 0',\n",
       " 'нет 0',\n",
       " 'Принимали 0',\n",
       " 'в 0',\n",
       " 'моно 0',\n",
       " 'или 0',\n",
       " 'на 0',\n",
       " 'фоне 0',\n",
       " 'АД B-MED',\n",
       " 'Моно 0',\n",
       " 'принимал 0',\n",
       " 'Еще 0',\n",
       " 'из 0',\n",
       " 'побочек 0',\n",
       " 'давал 0',\n",
       " 'по 0',\n",
       " 'утрам 0',\n",
       " 'сильную 0',\n",
       " 'тревогу B-EFFECT',\n",
       " 'Похоже 0',\n",
       " 'он 0',\n",
       " 'у 0',\n",
       " 'меня 0',\n",
       " 'работает 0',\n",
       " 'как 0',\n",
       " 'аугментация 0',\n",
       " 'к 0',\n",
       " 'АД B-MED',\n",
       " 'Сегодня 0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2e6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "handler = open('train.txt', encoding='utf-8')\n",
    "ll = ['B-MED', 'I-MED', 'B-EFFECT', 'I-EFFECT', 'B-SICK', 'I-SICK', '0', 0]\n",
    "res_list = []\n",
    "for i in handler.readlines():\n",
    "  if i.split() and len(i.split()) > 1:\n",
    "    if re.match(r'\\w+', i) and i.split()[1] in ll:\n",
    "      res_list.append(f'{i.split()[0]} {i.split()[1]}')\n",
    "handler.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fbf9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всего данных после фильтров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874e5a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3176"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea15710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из них экземпляров классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53545665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 нейролептики, 85 эффекты, 19 болезни\n"
     ]
    }
   ],
   "source": [
    "medicine = 0\n",
    "effects = 0\n",
    "sick = 0\n",
    "for i in set(res_list):\n",
    "    \n",
    "    if 'B-MED' in i or 'I-MED' in i:\n",
    "        medicine +=1\n",
    "    elif 'B-EFFECT' in i or 'I-EFFECT' in i:\n",
    "        effects +=1\n",
    "    elif 'B-SICK' in i or 'I-SICK' in i:\n",
    "        sick +=1\n",
    "print(f'{medicine} нейролептики, {effects} эффекты, {sick} болезни')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5065605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\tonstart.log  onstart.sh  tmp_test.txt  tmp_train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!mv train.txt tmp_train.txt\n",
    "!mv test.txt tmp_test.txt\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1280ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['клинические', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['карипразин', 'B-MED']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(open('tmp_train.txt').readlines()[0].split())\n",
    "open('tmp_train.txt').readlines()[10].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f38bdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84710dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = open('tmp_test.txt', encoding='utf-8')\n",
    "wr = open('test.txt', 'w', encoding='utf-8')\n",
    "ll = ['B-MED', 'I-MED', 'B-EFFECT', 'I-EFFECT', 'B-SICK', 'I-SICK', '0', 0]\n",
    "# print(len(handler.readlines()))\n",
    "for i in handler.readlines():\n",
    "  i = i.replace('\\t', ' ')\n",
    "  if i == '\\n':\n",
    "    # print('yep')\n",
    "    wr.write('\\n')\n",
    "  if i.split() and len(i.split()) > 1:\n",
    "    if re.match(r'\\w+', i) and i.split()[1] in ll:\n",
    "      wr.write(f'{i.split()[0]} {i.split()[1]}\\n')\n",
    "wr.close()\n",
    "handler.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99f1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = open('tmp_train.txt', encoding='utf-8')\n",
    "wr = open('train.txt', 'w', encoding='utf-8')\n",
    "ll = ['B-MED', 'I-MED', 'B-EFFECT', 'I-EFFECT', 'B-SICK', 'I-SICK', '0', 0]\n",
    "# print(len(handler.readlines()))\n",
    "for i in handler.readlines():\n",
    "  i = i.replace('\\t', ' ')\n",
    "  if i == '\\n':\n",
    "    # print('yep')\n",
    "    wr.write('\\n')\n",
    "  if i.split() and len(i.split()) > 1:\n",
    "    if re.match(r'\\w+', i) and i.split()[1] in ll:\n",
    "      wr.write(f'{i.split()[0]} {i.split()[1]}\\n')\n",
    "wr.close()\n",
    "handler.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05923840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-12 20:04:32--  https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/valid.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8007 (7.8K) [text/plain]\n",
      "Saving to: ‘valid.txt’\n",
      "\n",
      "valid.txt           100%[===================>]   7.82K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-04-12 20:04:32 (105 MB/s) - ‘valid.txt’ saved [8007/8007]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DmitryKutsev/cross-document_coreference/main/data/few_shot_bert/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e086ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5e6874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'class_name': 'conll2003_reader',\n",
       "  'data_path': '{DOWNLOADS_PATH}/ontonotes/',\n",
       "  'dataset_name': 'ontonotes',\n",
       "  'provide_pos': False},\n",
       " 'dataset_iterator': {'class_name': 'data_learning_iterator'},\n",
       " 'chainer': {'in': ['x'],\n",
       "  'in_y': ['y'],\n",
       "  'pipe': [{'class_name': 'bert_ner_preprocessor',\n",
       "    'vocab_file': '{BERT_PATH}/vocab.txt',\n",
       "    'do_lower_case': False,\n",
       "    'max_seq_length': 512,\n",
       "    'max_subword_length': 15,\n",
       "    'token_masking_prob': 0.0,\n",
       "    'in': ['x'],\n",
       "    'out': ['x_tokens',\n",
       "     'x_subword_tokens',\n",
       "     'x_subword_tok_ids',\n",
       "     'startofword_markers',\n",
       "     'attention_mask']},\n",
       "   {'id': 'tag_vocab',\n",
       "    'class_name': 'simple_vocab',\n",
       "    'unk_token': ['O'],\n",
       "    'pad_with_zeros': True,\n",
       "    'save_path': '{NER_PATH}/tag.dict',\n",
       "    'load_path': '{NER_PATH}/tag.dict',\n",
       "    'fit_on': ['y'],\n",
       "    'in': ['y'],\n",
       "    'out': ['y_ind']},\n",
       "   {'class_name': 'bert_sequence_tagger',\n",
       "    'n_tags': '#tag_vocab.len',\n",
       "    'keep_prob': 0.1,\n",
       "    'bert_config_file': '{BERT_PATH}/bert_config.json',\n",
       "    'pretrained_bert': '{BERT_PATH}/bert_model.ckpt',\n",
       "    'attention_probs_keep_prob': 0.5,\n",
       "    'use_crf': True,\n",
       "    'return_probas': False,\n",
       "    'ema_decay': 0.9,\n",
       "    'encoder_layer_ids': [-1],\n",
       "    'weight_decay_rate': 1e-06,\n",
       "    'learning_rate': 0.01,\n",
       "    'bert_learning_rate': 2e-05,\n",
       "    'min_learning_rate': 1e-07,\n",
       "    'learning_rate_drop_patience': 30,\n",
       "    'learning_rate_drop_div': 1.5,\n",
       "    'load_before_drop': False,\n",
       "    'clip_norm': 1.0,\n",
       "    'save_path': '{NER_PATH}/model',\n",
       "    'load_path': '{NER_PATH}/model',\n",
       "    'in': ['x_subword_tok_ids', 'attention_mask', 'startofword_markers'],\n",
       "    'in_y': ['y_ind'],\n",
       "    'out': ['y_pred_ind']},\n",
       "   {'ref': 'tag_vocab', 'in': ['y_pred_ind'], 'out': ['y_pred']}],\n",
       "  'out': ['x_tokens', 'y_pred']},\n",
       " 'train': {'epochs': 30,\n",
       "  'batch_size': 16,\n",
       "  'metrics': [{'name': 'ner_f1', 'inputs': ['y', 'y_pred']},\n",
       "   {'name': 'ner_token_f1', 'inputs': ['y', 'y_pred']}],\n",
       "  'validation_patience': 100,\n",
       "  'val_every_n_batches': 20,\n",
       "  'log_every_n_batches': 20,\n",
       "  'tensorboard_log_dir': '{NER_PATH}/logs',\n",
       "  'pytest_max_batches': 2,\n",
       "  'pytest_batch_size': '4',\n",
       "  'show_examples': False,\n",
       "  'evaluation_targets': ['valid', 'test'],\n",
       "  'class_name': 'nn_trainer'},\n",
       " 'metadata': {'variables': {'ROOT_PATH': '~/.deeppavlov',\n",
       "   'DOWNLOADS_PATH': '{ROOT_PATH}/downloads',\n",
       "   'MODELS_PATH': '{ROOT_PATH}/models',\n",
       "   'BERT_PATH': '{DOWNLOADS_PATH}/bert_models/multi_cased_L-12_H-768_A-12',\n",
       "   'NER_PATH': '{MODELS_PATH}/ner_ontonotes_bert_mult'},\n",
       "  'requirements': ['{DEEPPAVLOV_PATH}/requirements/tf.txt',\n",
       "   '{DEEPPAVLOV_PATH}/requirements/bert_dp.txt'],\n",
       "  'download': [{'url': 'http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz',\n",
       "    'subdir': '{MODELS_PATH}'},\n",
       "   {'url': 'http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip',\n",
       "    'subdir': '{DOWNLOADS_PATH}/bert_models'}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37eff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 30,\n",
       " 'batch_size': 4,\n",
       " 'metrics': [{'name': 'ner_f1', 'inputs': ['y', 'y_pred']},\n",
       "  {'name': 'ner_token_f1', 'inputs': ['y', 'y_pred']}],\n",
       " 'validation_patience': 100,\n",
       " 'val_every_n_batches': 20,\n",
       " 'log_every_n_batches': 20,\n",
       " 'tensorboard_log_dir': '{NER_PATH}/logs',\n",
       " 'pytest_max_batches': 2,\n",
       " 'pytest_batch_size': 4,\n",
       " 'show_examples': False,\n",
       " 'evaluation_targets': ['valid', 'test'],\n",
       " 'class_name': 'nn_trainer'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_config['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551ab035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_config['train']['pytest_batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7647119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_config['metadata']['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d838035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from deeppavlov import configs, build_model, train_model\n",
    "\n",
    "with configs.ner.ner_ontonotes_bert_mult.open(encoding='utf8') as f:\n",
    "    ner_config = json.load(f)\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
    "ner_config['train']['pytest_batch_size']=4\n",
    "ner_config['device']='GPU'\n",
    "ner_config['dataset_reader']['data_path'] = './'  # directory with train.txt, valid.txt and test.txt files\n",
    "ner_config['metadata']['variables']['NER_PATH'] = './'\n",
    "ner_config['metadata']['download'] = [ner_config['metadata']['download'][-1]]\n",
    "ner_config['train']['batch_size'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cf47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7214d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 21:24:18.761 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "2021-04-12 21:24:18.775 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/trainers/nn_trainer.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2021-04-12 21:24:26.784 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/tag.dict]\n",
      "2021-04-12 21:24:26.801 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 21:25:00.802 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:255: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 21:25:22.581 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best ner_f1 of 4.3406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 34, \"metrics\": {\"ner_f1\": 4.3406, \"ner_token_f1\": 2.3339}, \"time_spent\": \"0:00:13\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    }
   ],
   "source": [
    "ner_model = train_model(ner_config, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanika = ner_model(['Паксил норм. Принимал около года, щас перерыв. \\\n",
    "  Синдром отмены не то чтобы совсем отсутствует, но мне особых непрятностей не доставил. \\\n",
    "  Еще тироксин в качестве антидепрессанта хорош, хотя формально показания у него другие.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff47353",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(nanika[0][0], nanika[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed680a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
